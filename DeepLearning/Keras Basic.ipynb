{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "reported-shopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "taken-catalyst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0-rc0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "considered-reporter",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "educated-distribution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-polyester",
   "metadata": {},
   "source": [
    "# 1. 이미지 분류기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-eagle",
   "metadata": {},
   "source": [
    "## 데이터셋 적재하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "subjective-centre",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "later-winning",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "published-migration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "respective-payroll",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "boxed-bearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000]/255.0, X_train_full[5000:]/255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "working-greene",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-SHirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-faith",
   "metadata": {},
   "source": [
    "## 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "attempted-hybrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "lucky-duration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-helicopter",
   "metadata": {},
   "source": [
    "## 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "periodic-memphis",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-posting",
   "metadata": {},
   "source": [
    "## 모델 훈련과 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "unique-nickel",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 1s 594us/step - loss: 0.9643 - accuracy: 0.6867 - val_loss: 0.5101 - val_accuracy: 0.8244\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 1s 507us/step - loss: 0.5008 - accuracy: 0.8239 - val_loss: 0.4602 - val_accuracy: 0.8472\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 1s 501us/step - loss: 0.4480 - accuracy: 0.8422 - val_loss: 0.4368 - val_accuracy: 0.8432\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 1s 504us/step - loss: 0.4184 - accuracy: 0.8526 - val_loss: 0.4137 - val_accuracy: 0.8526\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 1s 502us/step - loss: 0.4009 - accuracy: 0.8586 - val_loss: 0.3741 - val_accuracy: 0.8712\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 1s 506us/step - loss: 0.3766 - accuracy: 0.8688 - val_loss: 0.3707 - val_accuracy: 0.8672\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 1s 505us/step - loss: 0.3665 - accuracy: 0.8717 - val_loss: 0.3849 - val_accuracy: 0.8600\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 1s 502us/step - loss: 0.3565 - accuracy: 0.8723 - val_loss: 0.3693 - val_accuracy: 0.8704\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 1s 504us/step - loss: 0.3491 - accuracy: 0.8779 - val_loss: 0.3455 - val_accuracy: 0.8788\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 1s 503us/step - loss: 0.3348 - accuracy: 0.8794 - val_loss: 0.3363 - val_accuracy: 0.8824\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 1s 508us/step - loss: 0.3229 - accuracy: 0.8856 - val_loss: 0.3397 - val_accuracy: 0.8806\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 1s 506us/step - loss: 0.3245 - accuracy: 0.8855 - val_loss: 0.3292 - val_accuracy: 0.8818\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 1s 513us/step - loss: 0.3065 - accuracy: 0.8912 - val_loss: 0.3590 - val_accuracy: 0.8682\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 1s 508us/step - loss: 0.3059 - accuracy: 0.8920 - val_loss: 0.3185 - val_accuracy: 0.8856\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 1s 508us/step - loss: 0.3005 - accuracy: 0.8939 - val_loss: 0.3243 - val_accuracy: 0.8842\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 1s 507us/step - loss: 0.2909 - accuracy: 0.8952 - val_loss: 0.3236 - val_accuracy: 0.8814\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 1s 507us/step - loss: 0.2843 - accuracy: 0.8981 - val_loss: 0.3177 - val_accuracy: 0.8866\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 1s 509us/step - loss: 0.2798 - accuracy: 0.8985 - val_loss: 0.3127 - val_accuracy: 0.8894\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 1s 513us/step - loss: 0.2737 - accuracy: 0.9028 - val_loss: 0.3303 - val_accuracy: 0.8832\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 1s 519us/step - loss: 0.2694 - accuracy: 0.9019 - val_loss: 0.3128 - val_accuracy: 0.8886\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 1s 509us/step - loss: 0.2673 - accuracy: 0.9057 - val_loss: 0.3127 - val_accuracy: 0.8862\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 1s 511us/step - loss: 0.2627 - accuracy: 0.9064 - val_loss: 0.3049 - val_accuracy: 0.8882\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 1s 513us/step - loss: 0.2600 - accuracy: 0.9077 - val_loss: 0.3034 - val_accuracy: 0.8936\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 1s 510us/step - loss: 0.2538 - accuracy: 0.9091 - val_loss: 0.3009 - val_accuracy: 0.8926\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 1s 510us/step - loss: 0.2460 - accuracy: 0.9125 - val_loss: 0.3026 - val_accuracy: 0.8886\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 1s 509us/step - loss: 0.2438 - accuracy: 0.9127 - val_loss: 0.3064 - val_accuracy: 0.8920\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 1s 509us/step - loss: 0.2325 - accuracy: 0.9163 - val_loss: 0.3065 - val_accuracy: 0.8892\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 1s 510us/step - loss: 0.2360 - accuracy: 0.9152 - val_loss: 0.2990 - val_accuracy: 0.8908\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 1s 508us/step - loss: 0.2293 - accuracy: 0.9169 - val_loss: 0.2855 - val_accuracy: 0.8962\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 1s 512us/step - loss: 0.2286 - accuracy: 0.9177 - val_loss: 0.2894 - val_accuracy: 0.8936\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "prescription-hepatitis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "solar-baltimore",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "graduate-treatment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 320us/step - loss: 0.3312 - accuracy: 0.8840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33115333318710327, 0.8840000033378601]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-plane",
   "metadata": {},
   "source": [
    "## 모델 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "changing-meditation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.1466222e-44,  0.0000000e+00,  8.9683102e-44, -0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -2.0000000e+00,\n",
       "         0.0000000e+00, -2.0000000e+00,  1.8664672e+08,  2.3549907e+20,\n",
       "         2.4821389e+05,  3.9505281e+30],\n",
       "       [ 6.8885191e+22,  1.4183974e-19,  6.7289760e+08,  9.1756927e+02,\n",
       "         5.3631910e-39,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00, -2.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "micro-transformation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -2.0000000e+00,\n",
       "         0.0000000e+00, -2.0000000e+00,  1.8664672e+08,  2.3549907e+20,\n",
       "         2.4821391e+05,  3.9505281e+30],\n",
       "       [ 6.8885191e+22,  0.0000000e+00,  6.7289760e+08,  9.1757001e+02,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00, -2.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "corresponding-kazakhstan",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yeomyungro/miniforge3/envs/atf24/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 9, 0])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-return",
   "metadata": {},
   "source": [
    "# 2. 주택 가격 예측(회귀)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "boolean-wrapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "prerequisite-allocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fabulous-authorization",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "contemporary-conservative",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "sunrise-panic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 520us/step - loss: 1.4272 - val_loss: 0.6015\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 374us/step - loss: 0.5472 - val_loss: 0.5049\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 370us/step - loss: 0.4787 - val_loss: 0.5204\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 368us/step - loss: 0.4752 - val_loss: 0.5085\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 364us/step - loss: 0.5159 - val_loss: 0.4709\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 363us/step - loss: 0.4315 - val_loss: 0.4593\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 671us/step - loss: 0.4547 - val_loss: 0.4559\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 370us/step - loss: 0.4100 - val_loss: 0.4647\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 368us/step - loss: 0.4317 - val_loss: 0.4658\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 367us/step - loss: 0.4359 - val_loss: 0.4430\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 365us/step - loss: 0.4324 - val_loss: 0.4335\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 365us/step - loss: 0.4232 - val_loss: 0.4318\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 368us/step - loss: 0.3889 - val_loss: 0.4254\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 378us/step - loss: 0.4158 - val_loss: 0.4363\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 416us/step - loss: 0.4051 - val_loss: 0.4325\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 367us/step - loss: 0.3958 - val_loss: 0.4232\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 375us/step - loss: 0.4632 - val_loss: 0.4342\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 393us/step - loss: 0.4001 - val_loss: 0.4886\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 369us/step - loss: 0.4047 - val_loss: 0.4208\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 372us/step - loss: 0.3751 - val_loss: 0.4208\n",
      "162/162 [==============================] - 0s 223us/step - loss: 0.3959\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "british-tuition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3959297239780426\n"
     ]
    }
   ],
   "source": [
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "departmental-attachment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 : 3.075, 정답 : 2.261, 차이(절대값) : 0.814\n",
      "예측 : 0.878, 정답 : 0.698, 차이(절대값) : 0.180\n",
      "예측 : 1.391, 정답 : 1.075, 차이(절대값) : 0.316\n"
     ]
    }
   ],
   "source": [
    "for pred, answer in zip(y_pred, y_test):\n",
    "    print(\"예측 : {:0.3f}, 정답 : {}, 차이(절대값) : {:0.3f}\".format(pred[0], answer, abs(pred[0]-answer)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-vegetable",
   "metadata": {},
   "source": [
    "# 3. 함수형 API를 사용해 복잡한 모델 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-anatomy",
   "metadata": {},
   "source": [
    "Wide&Deep 신경망 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "naughty-mapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "grateful-necklace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 30)           270         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 30)           930         dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 38)           0           input_4[0][0]                    \n",
      "                                                                 dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 1)            39          concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "large-sperm",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 596us/step - loss: 2.8786 - val_loss: 0.8514\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 440us/step - loss: 0.8340 - val_loss: 0.7582\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 442us/step - loss: 0.7347 - val_loss: 0.7139\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 445us/step - loss: 0.6788 - val_loss: 0.6707\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 732us/step - loss: 0.6400 - val_loss: 0.6357\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 588us/step - loss: 0.5967 - val_loss: 0.6106\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 452us/step - loss: 0.6399 - val_loss: 0.5896\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 451us/step - loss: 0.5581 - val_loss: 0.5718\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 450us/step - loss: 0.5348 - val_loss: 0.5610\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 452us/step - loss: 0.5175 - val_loss: 0.5483\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 452us/step - loss: 0.5175 - val_loss: 0.5389\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 451us/step - loss: 0.5225 - val_loss: 0.5287\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 448us/step - loss: 0.4948 - val_loss: 0.5232\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 448us/step - loss: 0.4705 - val_loss: 0.5208\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 448us/step - loss: 0.4876 - val_loss: 0.5124\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 449us/step - loss: 0.4920 - val_loss: 0.5082\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 461us/step - loss: 0.4696 - val_loss: 0.5046\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 458us/step - loss: 0.4699 - val_loss: 0.4996\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 449us/step - loss: 0.4555 - val_loss: 0.4956\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 478us/step - loss: 0.4526 - val_loss: 0.4936\n",
      "162/162 [==============================] - 0s 256us/step - loss: 0.4596\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "attractive-controversy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45962586998939514\n"
     ]
    }
   ],
   "source": [
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-surface",
   "metadata": {},
   "source": [
    "일부 특성은 짧은 경로로 전달하고 다른 특성들(중복 가능)은 깊은 경로로 전달하고 싶은 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "white-blair",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "lasting-interview",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "deep_input (InputLayer)         [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 30)           210         deep_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "wide_input (InputLayer)         [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 30)           930         dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 35)           0           wide_input[0][0]                 \n",
      "                                                                 dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            36          concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,176\n",
      "Trainable params: 1,176\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "welsh-stylus",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 620us/step - loss: 3.7363 - val_loss: 0.9034\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 460us/step - loss: 0.8755 - val_loss: 0.7139\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 455us/step - loss: 0.6742 - val_loss: 0.6585\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 458us/step - loss: 0.6123 - val_loss: 0.6325\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 464us/step - loss: 0.6098 - val_loss: 0.6141\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 728us/step - loss: 0.5732 - val_loss: 0.5997\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 461us/step - loss: 0.5824 - val_loss: 0.5868\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 463us/step - loss: 0.5564 - val_loss: 0.5754\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 451us/step - loss: 0.5461 - val_loss: 0.5662\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 455us/step - loss: 0.5316 - val_loss: 0.5570\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 456us/step - loss: 0.5140 - val_loss: 0.5494\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 455us/step - loss: 0.5321 - val_loss: 0.5421\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 455us/step - loss: 0.5334 - val_loss: 0.5365\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 483us/step - loss: 0.5201 - val_loss: 0.5294\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 479us/step - loss: 0.5167 - val_loss: 0.5256\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 460us/step - loss: 0.5009 - val_loss: 0.5244\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 483us/step - loss: 0.4976 - val_loss: 0.5184\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 466us/step - loss: 0.4898 - val_loss: 0.5144\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 477us/step - loss: 0.4870 - val_loss: 0.5132\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 475us/step - loss: 0.4821 - val_loss: 0.5094\n",
      "162/162 [==============================] - 0s 275us/step - loss: 0.4882\n",
      "0.4881875216960907\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:,:5], X_train[:,2:]\n",
    "X_valid_A, X_valid_B = X_valid[:,:5], X_valid[:,2:]\n",
    "X_test_A, X_test_B = X_test[:,:5], X_test[:,2:]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-offer",
   "metadata": {},
   "source": [
    "# 4. 모델 저장과 복원"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-refund",
   "metadata": {},
   "source": [
    "## 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "dense-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-routine",
   "metadata": {},
   "source": [
    "## 모델 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-receiver",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-composer",
   "metadata": {},
   "source": [
    "## 훈련 도중 일정 간격으로 체크포인트 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-experience",
   "metadata": {},
   "source": [
    "매 에포크의 끝마다 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "defensive-palestine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 530us/step - loss: 0.4866 - val_loss: 0.5067\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 465us/step - loss: 0.4890 - val_loss: 0.5040\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 461us/step - loss: 0.4834 - val_loss: 0.5028\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 458us/step - loss: 0.4825 - val_loss: 0.4999\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 460us/step - loss: 0.4780 - val_loss: 0.4997\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 570us/step - loss: 0.4771 - val_loss: 0.4989\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 561us/step - loss: 0.4765 - val_loss: 0.4950\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 461us/step - loss: 0.4734 - val_loss: 0.4954\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 461us/step - loss: 0.4707 - val_loss: 0.4913\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.4720 - val_loss: 0.4900\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 456us/step - loss: 0.4736 - val_loss: 0.4876\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 458us/step - loss: 0.4679 - val_loss: 0.4862\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 456us/step - loss: 0.4671 - val_loss: 0.4858\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 458us/step - loss: 0.4632 - val_loss: 0.4833\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.4638 - val_loss: 0.4815\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 457us/step - loss: 0.4603 - val_loss: 0.4798\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 461us/step - loss: 0.4614 - val_loss: 0.4816\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 460us/step - loss: 0.4594 - val_loss: 0.4853\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 460us/step - loss: 0.4581 - val_loss: 0.4760\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 460us/step - loss: 0.4544 - val_loss: 0.4748\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\",\n",
    "                                                save_best_only=True) # 훈련 시 검증 세트를 이용할 때 최상의 검증 세트 점수에서만 모델 저장\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid),\n",
    "                    callbacks=[checkpoint_cb])\n",
    "model = keras.models.load_model(\"my_keras_model.h5\") # 최상의 모델로 복원"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-surveillance",
   "metadata": {},
   "source": [
    "일정 에포크(*patience* 매개변수로 지정) 동안 검증 세트에 대한 점수가 향상되지 않으면 훈련을 멈춤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-incentive",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                  restore_best_weights=True)\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid),\n",
    "                    callbacks=[chekcpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-stuart",
   "metadata": {},
   "source": [
    "keras.callbacks 패키지에 다른 종류의 콜백들이 많음(참고:https://keras.io/callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-assets",
   "metadata": {},
   "source": [
    "# 5. 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-disorder",
   "metadata": {},
   "source": [
    "* *GridSearchCV*나 *RandomizedSearchCV*를 사용해 하이퍼파라미터 공간을 탐색할 수 있음\n",
    "* 이렇게 하려면 케라스 모델을 사이킷런 추정기처럼 보이도록 수정해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "naked-queensland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "narrow-default",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "oriented-bouquet",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 0s 521us/step - loss: 1.8839 - val_loss: 0.6841\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 366us/step - loss: 0.6292 - val_loss: 0.6068\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 355us/step - loss: 0.5695 - val_loss: 0.5568\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 355us/step - loss: 0.5194 - val_loss: 0.5310\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 351us/step - loss: 0.5026 - val_loss: 0.5144\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 514us/step - loss: 0.5078 - val_loss: 0.5039\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 432us/step - loss: 0.4850 - val_loss: 0.4959\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 355us/step - loss: 0.4717 - val_loss: 0.4877\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 356us/step - loss: 0.4589 - val_loss: 0.4827\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 354us/step - loss: 0.4526 - val_loss: 0.4756\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 355us/step - loss: 0.4498 - val_loss: 0.4720\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 356us/step - loss: 0.4481 - val_loss: 0.4655\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 352us/step - loss: 0.4642 - val_loss: 0.4630\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 356us/step - loss: 0.4384 - val_loss: 0.4599\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 354us/step - loss: 0.4453 - val_loss: 0.4555\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 351us/step - loss: 0.4311 - val_loss: 0.4510\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 355us/step - loss: 0.4349 - val_loss: 0.4487\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 353us/step - loss: 0.4438 - val_loss: 0.4476\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 355us/step - loss: 0.4415 - val_loss: 0.4410\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 354us/step - loss: 0.4324 - val_loss: 0.4407\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 365us/step - loss: 0.4301 - val_loss: 0.4364\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 365us/step - loss: 0.4126 - val_loss: 0.4348\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 368us/step - loss: 0.4220 - val_loss: 0.4325\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 370us/step - loss: 0.4123 - val_loss: 0.4304\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 368us/step - loss: 0.4244 - val_loss: 0.4269\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 364us/step - loss: 0.3981 - val_loss: 0.4247\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 364us/step - loss: 0.3997 - val_loss: 0.4235\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 355us/step - loss: 0.4047 - val_loss: 0.4213\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 355us/step - loss: 0.4136 - val_loss: 0.4199\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 353us/step - loss: 0.3913 - val_loss: 0.4196\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 359us/step - loss: 0.3931 - val_loss: 0.4167\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 369us/step - loss: 0.4031 - val_loss: 0.4179\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 358us/step - loss: 0.3997 - val_loss: 0.4154\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 352us/step - loss: 0.4095 - val_loss: 0.4143\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 373us/step - loss: 0.3980 - val_loss: 0.4109\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 368us/step - loss: 0.4036 - val_loss: 0.4105\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 361us/step - loss: 0.3961 - val_loss: 0.4105\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 358us/step - loss: 0.3895 - val_loss: 0.4089\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 357us/step - loss: 0.3866 - val_loss: 0.4054\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 361us/step - loss: 0.4000 - val_loss: 0.4045\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 373us/step - loss: 0.3922 - val_loss: 0.4037\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 369us/step - loss: 0.3863 - val_loss: 0.4022\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 375us/step - loss: 0.3920 - val_loss: 0.4022\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 354us/step - loss: 0.3805 - val_loss: 0.4005\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 354us/step - loss: 0.3896 - val_loss: 0.4002\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 352us/step - loss: 0.3708 - val_loss: 0.3969\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 383us/step - loss: 0.3826 - val_loss: 0.3972\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 345us/step - loss: 0.3659 - val_loss: 0.3936\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 340us/step - loss: 0.3925 - val_loss: 0.3924\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 345us/step - loss: 0.3873 - val_loss: 0.3928\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 346us/step - loss: 0.3834 - val_loss: 0.3913\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 346us/step - loss: 0.3815 - val_loss: 0.3904\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 347us/step - loss: 0.3734 - val_loss: 0.3898\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 346us/step - loss: 0.3754 - val_loss: 0.3880\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 341us/step - loss: 0.3801 - val_loss: 0.3866\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 344us/step - loss: 0.3586 - val_loss: 0.3860\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 343us/step - loss: 0.3685 - val_loss: 0.3864\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 354us/step - loss: 0.3943 - val_loss: 0.3843\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 346us/step - loss: 0.3675 - val_loss: 0.3857\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 347us/step - loss: 0.3762 - val_loss: 0.3822\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 347us/step - loss: 0.3754 - val_loss: 0.3824\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 348us/step - loss: 0.3747 - val_loss: 0.3800\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 342us/step - loss: 0.3696 - val_loss: 0.3790\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 342us/step - loss: 0.3496 - val_loss: 0.3799\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 345us/step - loss: 0.3604 - val_loss: 0.3771\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 345us/step - loss: 0.3837 - val_loss: 0.3776\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 348us/step - loss: 0.3586 - val_loss: 0.3782\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 347us/step - loss: 0.3744 - val_loss: 0.3757\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 349us/step - loss: 0.3538 - val_loss: 0.3779\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 342us/step - loss: 0.3679 - val_loss: 0.3758\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 342us/step - loss: 0.3721 - val_loss: 0.3725\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 341us/step - loss: 0.3592 - val_loss: 0.3742\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 387us/step - loss: 0.3549 - val_loss: 0.3720\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 353us/step - loss: 0.3701 - val_loss: 0.3704\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 355us/step - loss: 0.3514 - val_loss: 0.3727\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 352us/step - loss: 0.3478 - val_loss: 0.3734\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 354us/step - loss: 0.3649 - val_loss: 0.3729\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 353us/step - loss: 0.3554 - val_loss: 0.3705\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 352us/step - loss: 0.3653 - val_loss: 0.3689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 349us/step - loss: 0.3706 - val_loss: 0.3718\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 344us/step - loss: 0.3412 - val_loss: 0.3696\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 344us/step - loss: 0.3526 - val_loss: 0.3659\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 450us/step - loss: 0.3579 - val_loss: 0.3642\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 498us/step - loss: 0.3523 - val_loss: 0.3655\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 370us/step - loss: 0.3527 - val_loss: 0.3646\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 349us/step - loss: 0.3442 - val_loss: 0.3623\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 403us/step - loss: 0.3566 - val_loss: 0.3633\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 361us/step - loss: 0.3560 - val_loss: 0.3627\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 360us/step - loss: 0.3528 - val_loss: 0.3714\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 342us/step - loss: 0.3608 - val_loss: 0.3629\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 347us/step - loss: 0.3601 - val_loss: 0.3634\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 375us/step - loss: 0.3830 - val_loss: 0.3626\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 350us/step - loss: 0.3482 - val_loss: 0.3608\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 344us/step - loss: 0.3586 - val_loss: 0.4037\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 342us/step - loss: 0.3476 - val_loss: 0.3605\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 342us/step - loss: 0.3544 - val_loss: 0.3585\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 340us/step - loss: 0.3599 - val_loss: 0.3586\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 342us/step - loss: 0.3528 - val_loss: 0.3574\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 0s 343us/step - loss: 0.3520 - val_loss: 0.3606\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 342us/step - loss: 0.3410 - val_loss: 0.3585\n",
      "162/162 [==============================] - 0s 214us/step - loss: 0.3595\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.python.keras.api._v2.keras' has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-639f255c58ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m               callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n\u001b[1;32m      4\u001b[0m \u001b[0mmse_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.python.keras.api._v2.keras' has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "              validation_data=(X_valid, y_valid),\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "mse_test = keras_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "alternative-defeat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3595332205295563\n"
     ]
    }
   ],
   "source": [
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-salad",
   "metadata": {},
   "source": [
    "사이킷런은 손실이 아니라 점수를 계산하기 때문에 출력 점수는 음수의 MSE임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "nearby-confidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "functioning-swiss",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs = {\n",
    "    \"n_hidden\": [0,1,2,3],\n",
    "    \"n_neurons\": np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "common-arnold",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 642us/step - loss: 4.0838 - val_loss: 1.2164\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 1.1054 - val_loss: 0.9168\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.8564 - val_loss: 0.8416\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.857 - 0s 424us/step - loss: 0.8458 - val_loss: 0.7972\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.7552 - val_loss: 0.7643\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.7792 - val_loss: 0.7376\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 410us/step - loss: 0.7154 - val_loss: 0.7152\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 412us/step - loss: 0.6611 - val_loss: 0.6955\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.6596 - val_loss: 0.6789\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.6808 - val_loss: 0.6639\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.6528 - val_loss: 0.6503\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: 0.6268 - val_loss: 0.6380\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.6231 - val_loss: 0.6266\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.6198 - val_loss: 0.6158\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.6084 - val_loss: 0.6061\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.5986 - val_loss: 0.5972\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.5812 - val_loss: 0.5892\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.5509 - val_loss: 0.5818\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.5650 - val_loss: 0.5748\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.5933 - val_loss: 0.5684\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.5384 - val_loss: 0.5621\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.5364 - val_loss: 0.5567\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.5531 - val_loss: 0.5516\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.5507 - val_loss: 0.5467\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.5321 - val_loss: 0.5424\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.4992 - val_loss: 0.5382\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.5157 - val_loss: 0.5343\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.5196 - val_loss: 0.5307\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.5177 - val_loss: 0.5268\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.5085 - val_loss: 0.5235\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.508 - 0s 421us/step - loss: 0.5090 - val_loss: 0.5203\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.5236 - val_loss: 0.5176\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 437us/step - loss: 0.5020 - val_loss: 0.5150\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.5012 - val_loss: 0.5125\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.4869 - val_loss: 0.5095\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.4860 - val_loss: 0.5072\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.4893 - val_loss: 0.5049\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.4940 - val_loss: 0.5031\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.4855 - val_loss: 0.5012\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 401us/step - loss: 0.4845 - val_loss: 0.4991\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.4822 - val_loss: 0.4975\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: 0.4922 - val_loss: 0.4956\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.4914 - val_loss: 0.4937\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.4777 - val_loss: 0.4923\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.4857 - val_loss: 0.4908\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.4715 - val_loss: 0.4889\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.4629 - val_loss: 0.4876\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.4546 - val_loss: 0.4862\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.4681 - val_loss: 0.4845\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.4691 - val_loss: 0.4833\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.4645 - val_loss: 0.4824\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.4557 - val_loss: 0.4811\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.4802 - val_loss: 0.4798\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.4724 - val_loss: 0.4787\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 437us/step - loss: 0.4701 - val_loss: 0.4777\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.4500 - val_loss: 0.4760\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 0.4447 - val_loss: 0.4749\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.4639 - val_loss: 0.4740\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.4568 - val_loss: 0.4730\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.4650 - val_loss: 0.4718\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.4337 - val_loss: 0.4710\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.4611 - val_loss: 0.4702\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.4509 - val_loss: 0.4690\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.4618 - val_loss: 0.4680\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.4442 - val_loss: 0.4670\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.4528 - val_loss: 0.4662\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.4499 - val_loss: 0.4653\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.4535 - val_loss: 0.4644\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.4662 - val_loss: 0.4638\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.4772 - val_loss: 0.4627\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: 0.4588 - val_loss: 0.4615\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.4233 - val_loss: 0.4611\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.4360 - val_loss: 0.4598\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 0.4419 - val_loss: 0.4590\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.4493 - val_loss: 0.4586\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.4455 - val_loss: 0.4579\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.4447 - val_loss: 0.4567\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.4443 - val_loss: 0.4561\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 436us/step - loss: 0.4547 - val_loss: 0.4553\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.4580 - val_loss: 0.4548\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.4393 - val_loss: 0.4539\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.4386 - val_loss: 0.4538\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.4576 - val_loss: 0.4525\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: 0.4325 - val_loss: 0.4519\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.4301 - val_loss: 0.4513\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.4393 - val_loss: 0.4506\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.4540 - val_loss: 0.4503\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.4535 - val_loss: 0.4495\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.4301 - val_loss: 0.4486\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.4280 - val_loss: 0.4486\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: 0.4622 - val_loss: 0.4478\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.4511 - val_loss: 0.4474\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: 0.4181 - val_loss: 0.4469\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.4468 - val_loss: 0.4461\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.4328 - val_loss: 0.4454\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.4104 - val_loss: 0.4447\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.4396 - val_loss: 0.4443\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.4225 - val_loss: 0.4439\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.4293 - val_loss: 0.4433\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.4443 - val_loss: 0.4428\n",
      "121/121 [==============================] - 0s 235us/step - loss: 0.4267\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 625us/step - loss: 4.7048 - val_loss: 1.5224\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 1.3125 - val_loss: 0.9037\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.8667 - val_loss: 0.7582\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.7209 - val_loss: 0.7104\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.6770 - val_loss: 0.6866\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.6300 - val_loss: 0.6691\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.6463 - val_loss: 0.6542\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.6528 - val_loss: 0.6406\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.6143 - val_loss: 0.6290\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.5973 - val_loss: 0.6184\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.5752 - val_loss: 0.6088\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.5757 - val_loss: 0.5993\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.5846 - val_loss: 0.5912\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.5579 - val_loss: 0.5836\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: 0.5544 - val_loss: 0.5769\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.5348 - val_loss: 0.5709\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 437us/step - loss: 0.5341 - val_loss: 0.5653\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.5296 - val_loss: 0.5594\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.5189 - val_loss: 0.5542\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.5070 - val_loss: 0.5500\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.5175 - val_loss: 0.5457\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 0.5129 - val_loss: 0.5418\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: 0.4993 - val_loss: 0.5381\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.5090 - val_loss: 0.5339\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.5116 - val_loss: 0.5308\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 410us/step - loss: 0.5062 - val_loss: 0.5279\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.4925 - val_loss: 0.5250\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 407us/step - loss: 0.5027 - val_loss: 0.5222\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.4813 - val_loss: 0.5197\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 404us/step - loss: 0.5090 - val_loss: 0.5174\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.4858 - val_loss: 0.5151\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.4893 - val_loss: 0.5126\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.4713 - val_loss: 0.5106\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.4761 - val_loss: 0.5087\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 412us/step - loss: 0.4696 - val_loss: 0.5072\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.4782 - val_loss: 0.5048\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.4754 - val_loss: 0.5033\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.4762 - val_loss: 0.5018\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.4761 - val_loss: 0.5002\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.4558 - val_loss: 0.4984\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.4720 - val_loss: 0.4968\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 412us/step - loss: 0.4540 - val_loss: 0.4953\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.4721 - val_loss: 0.4939\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.4721 - val_loss: 0.4926\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.4690 - val_loss: 0.4912\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.4514 - val_loss: 0.4898\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.4682 - val_loss: 0.4883\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 412us/step - loss: 0.4553 - val_loss: 0.4871\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 411us/step - loss: 0.4509 - val_loss: 0.4859\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.4566 - val_loss: 0.4845\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.4535 - val_loss: 0.4837\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4471 - val_loss: 0.4824\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.4805 - val_loss: 0.4813\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.4500 - val_loss: 0.4801\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.4563 - val_loss: 0.4790\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 412us/step - loss: 0.4664 - val_loss: 0.4784\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 414us/step - loss: 0.4565 - val_loss: 0.4772\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.4349 - val_loss: 0.4760\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 406us/step - loss: 0.4454 - val_loss: 0.4748\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 408us/step - loss: 0.4450 - val_loss: 0.4742\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 410us/step - loss: 0.4691 - val_loss: 0.4729\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.4740 - val_loss: 0.4717\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 411us/step - loss: 0.4284 - val_loss: 0.4707\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.4562 - val_loss: 0.4699\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 409us/step - loss: 0.4412 - val_loss: 0.4687\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.4489 - val_loss: 0.4679\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.4439 - val_loss: 0.4671\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.4338 - val_loss: 0.4663\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 408us/step - loss: 0.4508 - val_loss: 0.4655\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 412us/step - loss: 0.4330 - val_loss: 0.4650\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.4397 - val_loss: 0.4635\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 410us/step - loss: 0.4473 - val_loss: 0.4627\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.4471 - val_loss: 0.4618\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 408us/step - loss: 0.4414 - val_loss: 0.4610\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 412us/step - loss: 0.4392 - val_loss: 0.4603\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 411us/step - loss: 0.4384 - val_loss: 0.4596\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.4259 - val_loss: 0.4588\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 409us/step - loss: 0.4357 - val_loss: 0.4580\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 412us/step - loss: 0.4378 - val_loss: 0.4577\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 411us/step - loss: 0.4124 - val_loss: 0.4568\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 411us/step - loss: 0.4311 - val_loss: 0.4558\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 408us/step - loss: 0.4393 - val_loss: 0.4553\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.4342 - val_loss: 0.4547\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 411us/step - loss: 0.4320 - val_loss: 0.4540\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.4445 - val_loss: 0.4530\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.4302 - val_loss: 0.4524\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 410us/step - loss: 0.4258 - val_loss: 0.4520\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 410us/step - loss: 0.4339 - val_loss: 0.4511\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 407us/step - loss: 0.4085 - val_loss: 0.4506\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 409us/step - loss: 0.4229 - val_loss: 0.4502\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.4081 - val_loss: 0.4493\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.4469 - val_loss: 0.4491\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 408us/step - loss: 0.4266 - val_loss: 0.4484\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 410us/step - loss: 0.4118 - val_loss: 0.4476\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 412us/step - loss: 0.4264 - val_loss: 0.4474\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 412us/step - loss: 0.4380 - val_loss: 0.4470\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 412us/step - loss: 0.4218 - val_loss: 0.4465\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 409us/step - loss: 0.4220 - val_loss: 0.4461\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.4142 - val_loss: 0.4452\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 409us/step - loss: 0.4341 - val_loss: 0.4451\n",
      "121/121 [==============================] - 0s 227us/step - loss: 0.4591\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 4.6983 - val_loss: 1.3491\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 1.1754 - val_loss: 0.8134\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 437us/step - loss: 0.7830 - val_loss: 0.7322\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.6890 - val_loss: 0.7001\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.6903 - val_loss: 0.6771\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.6226 - val_loss: 0.6587\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.6301 - val_loss: 0.6422\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.5900 - val_loss: 0.6279\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.6175 - val_loss: 0.6152\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.5844 - val_loss: 0.6034\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.5983 - val_loss: 0.5926\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.5789 - val_loss: 0.5827\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.5813 - val_loss: 0.5743\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 412us/step - loss: 0.5553 - val_loss: 0.5664\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.5584 - val_loss: 0.5592\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.5488 - val_loss: 0.5524\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.5662 - val_loss: 0.5465\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.5332 - val_loss: 0.5407\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.4975 - val_loss: 0.5359\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.5429 - val_loss: 0.5308\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.5265 - val_loss: 0.5259\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.5209 - val_loss: 0.5222\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.4948 - val_loss: 0.5178\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.5071 - val_loss: 0.5143\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.5224 - val_loss: 0.5116\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.4788 - val_loss: 0.5075\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.5063 - val_loss: 0.5046\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.4945 - val_loss: 0.5021\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.4940 - val_loss: 0.4994\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.4768 - val_loss: 0.4965\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.4529 - val_loss: 0.4942\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.5014 - val_loss: 0.4920\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.4888 - val_loss: 0.4901\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.4789 - val_loss: 0.4883\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 422us/step - loss: 0.4785 - val_loss: 0.4863\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.4623 - val_loss: 0.4846\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.4634 - val_loss: 0.4833\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.4944 - val_loss: 0.4815\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 412us/step - loss: 0.4853 - val_loss: 0.4802\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.4630 - val_loss: 0.4778\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 412us/step - loss: 0.4633 - val_loss: 0.4768\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.4642 - val_loss: 0.4754\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 410us/step - loss: 0.4740 - val_loss: 0.4738\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.4612 - val_loss: 0.4725\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 411us/step - loss: 0.4611 - val_loss: 0.4714\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 412us/step - loss: 0.4663 - val_loss: 0.4701\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.4599 - val_loss: 0.4690\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.4675 - val_loss: 0.4676\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.4567 - val_loss: 0.4666\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.4642 - val_loss: 0.4655\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.4588 - val_loss: 0.4645\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 412us/step - loss: 0.4600 - val_loss: 0.4632\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.4730 - val_loss: 0.4628\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.4585 - val_loss: 0.4617\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.4395 - val_loss: 0.4607\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.4562 - val_loss: 0.4598\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.4676 - val_loss: 0.4589\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.4325 - val_loss: 0.4582\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 411us/step - loss: 0.4468 - val_loss: 0.4571\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.4634 - val_loss: 0.4564\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.4325 - val_loss: 0.4555\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.4452 - val_loss: 0.4546\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.4427 - val_loss: 0.4538\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.4463 - val_loss: 0.4531\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.4457 - val_loss: 0.4524\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.4455 - val_loss: 0.4515\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.4325 - val_loss: 0.4512\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.4366 - val_loss: 0.4501\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.4668 - val_loss: 0.4494\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.4369 - val_loss: 0.4488\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.4741 - val_loss: 0.4477\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.4451 - val_loss: 0.4474\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.4410 - val_loss: 0.4467\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.4327 - val_loss: 0.4460\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.4439 - val_loss: 0.4452\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.4200 - val_loss: 0.4446\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 411us/step - loss: 0.4303 - val_loss: 0.4438\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.4233 - val_loss: 0.4432\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.4409 - val_loss: 0.4427\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.4404 - val_loss: 0.4420\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.4241 - val_loss: 0.4415\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.4233 - val_loss: 0.4409\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.4241 - val_loss: 0.4404\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.4321 - val_loss: 0.4400\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.4317 - val_loss: 0.4393\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.4100 - val_loss: 0.4390\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.4419 - val_loss: 0.4384\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.4154 - val_loss: 0.4374\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.4106 - val_loss: 0.4370\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 412us/step - loss: 0.4290 - val_loss: 0.4368\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 411us/step - loss: 0.4667 - val_loss: 0.4363\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.4307 - val_loss: 0.4357\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.4333 - val_loss: 0.4351\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 411us/step - loss: 0.4246 - val_loss: 0.4343\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.4374 - val_loss: 0.4340\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 408us/step - loss: 0.4141 - val_loss: 0.4336\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.4326 - val_loss: 0.4328\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.4242 - val_loss: 0.4324\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.4322 - val_loss: 0.4323\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.4165 - val_loss: 0.4318\n",
      "121/121 [==============================] - 0s 231us/step - loss: 0.4204\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 1.6980 - val_loss: 0.5703\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 504us/step - loss: 0.5425 - val_loss: 0.4955\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.4739 - val_loss: 0.4562\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.4541 - val_loss: 0.4384\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 504us/step - loss: 0.3970 - val_loss: 0.4265\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.4155 - val_loss: 0.4128\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.3896 - val_loss: 0.4076\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 504us/step - loss: 0.4035 - val_loss: 0.4055\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.3814 - val_loss: 0.3898\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.3762 - val_loss: 0.3830\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 505us/step - loss: 0.3978 - val_loss: 0.3834\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.3731 - val_loss: 0.3693\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 509us/step - loss: 0.3627 - val_loss: 0.3695\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.3679 - val_loss: 0.3680\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.3432 - val_loss: 0.3588\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.3475 - val_loss: 0.3697\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.3627 - val_loss: 0.3589\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.3267 - val_loss: 0.3511\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.3350 - val_loss: 0.3640\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.3448 - val_loss: 0.3529\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.3444 - val_loss: 0.3543\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.3336 - val_loss: 0.3470\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.3549 - val_loss: 0.3384\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.3218 - val_loss: 0.3389\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.3183 - val_loss: 0.3366\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.3331 - val_loss: 0.3306\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.3274 - val_loss: 0.3305\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.3420 - val_loss: 0.3377\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.3225 - val_loss: 0.3244\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.3198 - val_loss: 0.4130\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.3205 - val_loss: 0.3293\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.3025 - val_loss: 0.3271\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.2959 - val_loss: 0.3564\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.2914 - val_loss: 0.3207\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.3107 - val_loss: 0.3336\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.2919 - val_loss: 0.3334\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.3026 - val_loss: 0.3205\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.2926 - val_loss: 0.3198\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.3097 - val_loss: 0.3395\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.2938 - val_loss: 0.3293\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.2859 - val_loss: 0.3177\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.2905 - val_loss: 0.3277\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.2933 - val_loss: 0.3101\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.2998 - val_loss: 0.3231\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.2876 - val_loss: 0.3093\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.2962 - val_loss: 0.3207\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.2690 - val_loss: 0.3497\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.2905 - val_loss: 0.3338\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.2879 - val_loss: 0.3118\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.2876 - val_loss: 0.3162\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.2821 - val_loss: 0.3177\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.2779 - val_loss: 0.3235\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.2566 - val_loss: 0.3125\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.2878 - val_loss: 0.3166\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.2902 - val_loss: 0.3279\n",
      "121/121 [==============================] - 0s 240us/step - loss: 0.3211\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 711us/step - loss: 1.8886 - val_loss: 0.5882\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.5576 - val_loss: 0.5313\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.4821 - val_loss: 0.4702\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.4544 - val_loss: 0.4577\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.4371 - val_loss: 0.4306\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.4125 - val_loss: 0.4146\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.3995 - val_loss: 0.4074\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.3874 - val_loss: 0.3975\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.3825 - val_loss: 0.3890\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.3721 - val_loss: 0.3826\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.3593 - val_loss: 0.3777\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.3646 - val_loss: 0.3678\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.3746 - val_loss: 0.3651\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 535us/step - loss: 0.3571 - val_loss: 0.3678\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3506 - val_loss: 0.3601\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3476 - val_loss: 0.3661\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3403 - val_loss: 0.3619\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.3298 - val_loss: 0.3564\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3314 - val_loss: 0.3434\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 525us/step - loss: 0.3451 - val_loss: 0.3500\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.3342 - val_loss: 0.3409\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.3249 - val_loss: 0.3352\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.3305 - val_loss: 0.3324\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.3388 - val_loss: 0.3286\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.3136 - val_loss: 0.3422\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.3273 - val_loss: 0.3242\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3180 - val_loss: 0.3386\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 520us/step - loss: 0.3123 - val_loss: 0.3361\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.3130 - val_loss: 0.3341\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3178 - val_loss: 0.3169\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.2882 - val_loss: 0.3317\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.2978 - val_loss: 0.3154\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.3034 - val_loss: 0.3163\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3092 - val_loss: 0.3276\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.2961 - val_loss: 0.3203\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 470us/step - loss: 0.3031 - val_loss: 0.3201\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.2832 - val_loss: 0.3124\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.3056 - val_loss: 0.3320\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3003 - val_loss: 0.3206\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.2799 - val_loss: 0.3116\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 514us/step - loss: 0.2860 - val_loss: 0.3141\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.2929 - val_loss: 0.3144\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.2906 - val_loss: 0.3213\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.2700 - val_loss: 0.3118\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.2907 - val_loss: 0.3166\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.2849 - val_loss: 0.3167\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.2741 - val_loss: 0.3043\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.2934 - val_loss: 0.3041\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.2853 - val_loss: 0.3025\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.2675 - val_loss: 0.3251\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 518us/step - loss: 0.2803 - val_loss: 0.3062\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2705 - val_loss: 0.3265\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.2883 - val_loss: 0.3311\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.2728 - val_loss: 0.3084\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2654 - val_loss: 0.3150\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.2780 - val_loss: 0.3023\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.2857 - val_loss: 0.3248\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.2949 - val_loss: 0.3037\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.2635 - val_loss: 0.2978\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.2603 - val_loss: 0.3056\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.2635 - val_loss: 0.3023\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.2672 - val_loss: 0.3117\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.2641 - val_loss: 0.3041\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.2752 - val_loss: 0.3003\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.2591 - val_loss: 0.3012\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.2731 - val_loss: 0.3032\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.2607 - val_loss: 0.3045\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.2561 - val_loss: 0.2967\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.2545 - val_loss: 0.2960\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.2678 - val_loss: 0.3095\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.2541 - val_loss: 0.2960\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.2624 - val_loss: 0.3045\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.2695 - val_loss: 0.3154\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.2578 - val_loss: 0.3278\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.2782 - val_loss: 0.3095\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2645 - val_loss: 0.3391\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.2583 - val_loss: 0.2968\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.2453 - val_loss: 0.2953\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.2548 - val_loss: 0.3022\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.2526 - val_loss: 0.2959\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.2556 - val_loss: 0.3079\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.2592 - val_loss: 0.3089\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.2611 - val_loss: 0.3367\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.2556 - val_loss: 0.3068\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.2594 - val_loss: 0.3243\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.2578 - val_loss: 0.2992\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.2466 - val_loss: 0.3123\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.2450 - val_loss: 0.2993\n",
      "121/121 [==============================] - 0s 245us/step - loss: 0.3152\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 704us/step - loss: 1.9497 - val_loss: 0.6265\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.5838 - val_loss: 0.5376\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.5121 - val_loss: 0.4837\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.4718 - val_loss: 0.4526\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.4365 - val_loss: 0.4286\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.4323 - val_loss: 0.4120\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3912 - val_loss: 0.4047\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3832 - val_loss: 0.3957\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3995 - val_loss: 0.3888\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3628 - val_loss: 0.3781\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.3822 - val_loss: 0.3777\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3627 - val_loss: 0.3676\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.3631 - val_loss: 0.3623\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.3589 - val_loss: 0.3583\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3703 - val_loss: 0.3616\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3773 - val_loss: 0.3616\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3559 - val_loss: 0.3489\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.3211 - val_loss: 0.3533\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3424 - val_loss: 0.3431\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.3538 - val_loss: 0.3483\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3267 - val_loss: 0.3386\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3310 - val_loss: 0.3443\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3240 - val_loss: 0.3342\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.3176 - val_loss: 0.3304\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3181 - val_loss: 0.3276\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 480us/step - loss: 0.3183 - val_loss: 0.3272\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3224 - val_loss: 0.3227\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3198 - val_loss: 0.3265\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3071 - val_loss: 0.3258\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3028 - val_loss: 0.3219\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3081 - val_loss: 0.3271\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.3036 - val_loss: 0.3181\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.2919 - val_loss: 0.3265\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.2985 - val_loss: 0.3172\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.3000 - val_loss: 0.3377\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.2932 - val_loss: 0.3266\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.3025 - val_loss: 0.3178\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.3109 - val_loss: 0.3121\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3086 - val_loss: 0.3136\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3034 - val_loss: 0.3149\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.2999 - val_loss: 0.3250\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3016 - val_loss: 0.3096\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.2854 - val_loss: 0.3087\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.2750 - val_loss: 0.3147\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.2939 - val_loss: 0.3061\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.2948 - val_loss: 0.3100\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.2898 - val_loss: 0.3053\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.2830 - val_loss: 0.3210\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.2729 - val_loss: 0.3297\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.2763 - val_loss: 0.3047\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.2852 - val_loss: 0.3040\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.2840 - val_loss: 0.3058\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.2811 - val_loss: 0.3079\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.2732 - val_loss: 0.3002\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 554us/step - loss: 0.2676 - val_loss: 0.3032\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.2803 - val_loss: 0.3101\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.2916 - val_loss: 0.3037\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 566us/step - loss: 0.2810 - val_loss: 0.2980\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.2721 - val_loss: 0.3122\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.2838 - val_loss: 0.2961\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.2699 - val_loss: 0.2996\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.2726 - val_loss: 0.3260\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.2762 - val_loss: 0.3450\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 517us/step - loss: 0.2872 - val_loss: 0.3061\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.2766 - val_loss: 0.3098\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.2886 - val_loss: 0.3027\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 518us/step - loss: 0.2616 - val_loss: 0.3015\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 514us/step - loss: 0.2667 - val_loss: 0.2965\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.2768 - val_loss: 0.2948\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2680 - val_loss: 0.2997\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.2633 - val_loss: 0.3035\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 524us/step - loss: 0.2690 - val_loss: 0.2987\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.2589 - val_loss: 0.3028\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 520us/step - loss: 0.2756 - val_loss: 0.2946\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.2612 - val_loss: 0.2936\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 530us/step - loss: 0.2553 - val_loss: 0.2937\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 517us/step - loss: 0.2564 - val_loss: 0.3151\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.2655 - val_loss: 0.2955\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.2495 - val_loss: 0.3014\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 516us/step - loss: 0.2697 - val_loss: 0.2988\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.2474 - val_loss: 0.2998\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.2648 - val_loss: 0.3112\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 537us/step - loss: 0.2577 - val_loss: 0.2956\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 518us/step - loss: 0.2667 - val_loss: 0.2958\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 516us/step - loss: 0.2477 - val_loss: 0.3030\n",
      "121/121 [==============================] - 0s 249us/step - loss: 0.3097\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 596us/step - loss: 6.3290 - val_loss: 4.9743\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 386us/step - loss: 4.4465 - val_loss: 3.6040\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 393us/step - loss: 3.3622 - val_loss: 2.6911\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 384us/step - loss: 2.5023 - val_loss: 2.0729\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 382us/step - loss: 1.9282 - val_loss: 1.6498\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 384us/step - loss: 1.5886 - val_loss: 1.3568\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 386us/step - loss: 1.3122 - val_loss: 1.1527\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 390us/step - loss: 1.2228 - val_loss: 1.0090\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 385us/step - loss: 1.0161 - val_loss: 0.9071\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 384us/step - loss: 0.9071 - val_loss: 0.8343\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 387us/step - loss: 0.7689 - val_loss: 0.7817\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 380us/step - loss: 0.8137 - val_loss: 0.7436\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 373us/step - loss: 0.7587 - val_loss: 0.7156\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 360us/step - loss: 0.7191 - val_loss: 0.6947\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 365us/step - loss: 0.6720 - val_loss: 0.6788\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 362us/step - loss: 0.7318 - val_loss: 0.6667\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 369us/step - loss: 0.6326 - val_loss: 0.6572\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 366us/step - loss: 0.6379 - val_loss: 0.6496\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 358us/step - loss: 0.6599 - val_loss: 0.6435\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 371us/step - loss: 0.6132 - val_loss: 0.6384\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 365us/step - loss: 0.6294 - val_loss: 0.6340\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 371us/step - loss: 0.6350 - val_loss: 0.6302\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 357us/step - loss: 0.6074 - val_loss: 0.6269\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 366us/step - loss: 0.6385 - val_loss: 0.6239\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 355us/step - loss: 0.6060 - val_loss: 0.6211\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 357us/step - loss: 0.6221 - val_loss: 0.6186\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 365us/step - loss: 0.6358 - val_loss: 0.6162\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 361us/step - loss: 0.5876 - val_loss: 0.6140\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 359us/step - loss: 0.6142 - val_loss: 0.6119\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 357us/step - loss: 0.5991 - val_loss: 0.6099\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 368us/step - loss: 0.5945 - val_loss: 0.6079\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 341us/step - loss: 0.6029 - val_loss: 0.6061\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 357us/step - loss: 0.5873 - val_loss: 0.6043\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 358us/step - loss: 0.6018 - val_loss: 0.6026\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 361us/step - loss: 0.5842 - val_loss: 0.6009\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 369us/step - loss: 0.5771 - val_loss: 0.5993\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 354us/step - loss: 0.6115 - val_loss: 0.5977\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 359us/step - loss: 0.5872 - val_loss: 0.5962\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 362us/step - loss: 0.5824 - val_loss: 0.5947\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 366us/step - loss: 0.5911 - val_loss: 0.5932\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 354us/step - loss: 0.5804 - val_loss: 0.5918\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 358us/step - loss: 0.5936 - val_loss: 0.5904\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 362us/step - loss: 0.5800 - val_loss: 0.5891\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 361us/step - loss: 0.5797 - val_loss: 0.5878\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 355us/step - loss: 0.5933 - val_loss: 0.5865\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 357us/step - loss: 0.5789 - val_loss: 0.5853\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 367us/step - loss: 0.5772 - val_loss: 0.5841\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 361us/step - loss: 0.5724 - val_loss: 0.5829\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 342us/step - loss: 0.5633 - val_loss: 0.5818\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 361us/step - loss: 0.5652 - val_loss: 0.5806\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 355us/step - loss: 0.5662 - val_loss: 0.5796\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 363us/step - loss: 0.5627 - val_loss: 0.5785\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 360us/step - loss: 0.5605 - val_loss: 0.5775\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 356us/step - loss: 0.5659 - val_loss: 0.5765\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 359us/step - loss: 0.5681 - val_loss: 0.5755\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 367us/step - loss: 0.5839 - val_loss: 0.5745\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 364us/step - loss: 0.5851 - val_loss: 0.5736\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 357us/step - loss: 0.5660 - val_loss: 0.5727\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 362us/step - loss: 0.5711 - val_loss: 0.5718\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 371us/step - loss: 0.5327 - val_loss: 0.5709\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 354us/step - loss: 0.5630 - val_loss: 0.5701\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 359us/step - loss: 0.5635 - val_loss: 0.5693\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 358us/step - loss: 0.5711 - val_loss: 0.5685\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 364us/step - loss: 0.5657 - val_loss: 0.5677\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 355us/step - loss: 0.5689 - val_loss: 0.5670\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 360us/step - loss: 0.5527 - val_loss: 0.5662\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 360us/step - loss: 0.5457 - val_loss: 0.5655\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 369us/step - loss: 0.5458 - val_loss: 0.5649\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 355us/step - loss: 0.5252 - val_loss: 0.5642\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 364us/step - loss: 0.5630 - val_loss: 0.5635\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 359us/step - loss: 0.5463 - val_loss: 0.5629\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 355us/step - loss: 0.5430 - val_loss: 0.5622\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 360us/step - loss: 0.5488 - val_loss: 0.5616\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 360us/step - loss: 0.5637 - val_loss: 0.5610\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 360us/step - loss: 0.5206 - val_loss: 0.5605\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 354us/step - loss: 0.5359 - val_loss: 0.5599\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 358us/step - loss: 0.5457 - val_loss: 0.5594\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 360us/step - loss: 0.5572 - val_loss: 0.5588\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 368us/step - loss: 0.5377 - val_loss: 0.5583\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 342us/step - loss: 0.5602 - val_loss: 0.5578\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 361us/step - loss: 0.5496 - val_loss: 0.5573\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 362us/step - loss: 0.5541 - val_loss: 0.5568\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 359us/step - loss: 0.5271 - val_loss: 0.5564\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 361us/step - loss: 0.5503 - val_loss: 0.5559\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 362us/step - loss: 0.5543 - val_loss: 0.5555\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 366us/step - loss: 0.5244 - val_loss: 0.5551\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 366us/step - loss: 0.5349 - val_loss: 0.5546\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 356us/step - loss: 0.5402 - val_loss: 0.5542\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 358us/step - loss: 0.5502 - val_loss: 0.5538\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 366us/step - loss: 0.5324 - val_loss: 0.5535\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 360us/step - loss: 0.5510 - val_loss: 0.5531\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 364us/step - loss: 0.5482 - val_loss: 0.5527\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 366us/step - loss: 0.5425 - val_loss: 0.5524\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 360us/step - loss: 0.5326 - val_loss: 0.5520\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 357us/step - loss: 0.5370 - val_loss: 0.5517\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 359us/step - loss: 0.5391 - val_loss: 0.5514\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 369us/step - loss: 0.5609 - val_loss: 0.5511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 369us/step - loss: 0.5290 - val_loss: 0.5508\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 367us/step - loss: 0.5542 - val_loss: 0.5505\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 371us/step - loss: 0.5587 - val_loss: 0.5502\n",
      "121/121 [==============================] - 0s 205us/step - loss: 0.5268\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 559us/step - loss: 6.6794 - val_loss: 5.2421\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 385us/step - loss: 4.7484 - val_loss: 3.7989\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 373us/step - loss: 3.4774 - val_loss: 2.8189\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 383us/step - loss: 2.6836 - val_loss: 2.1487\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 370us/step - loss: 2.0018 - val_loss: 1.6867\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 385us/step - loss: 1.5596 - val_loss: 1.3675\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 371us/step - loss: 1.3317 - val_loss: 1.1462\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 380us/step - loss: 1.0817 - val_loss: 0.9919\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 372us/step - loss: 0.9263 - val_loss: 0.8843\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 383us/step - loss: 0.8536 - val_loss: 0.8088\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 369us/step - loss: 0.7593 - val_loss: 0.7554\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 382us/step - loss: 0.7325 - val_loss: 0.7178\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 369us/step - loss: 0.7084 - val_loss: 0.6907\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 382us/step - loss: 0.6469 - val_loss: 0.6712\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 370us/step - loss: 0.6357 - val_loss: 0.6569\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 380us/step - loss: 0.6278 - val_loss: 0.6462\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 367us/step - loss: 0.6292 - val_loss: 0.6382\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 379us/step - loss: 0.6153 - val_loss: 0.6318\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 370us/step - loss: 0.6141 - val_loss: 0.6268\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 382us/step - loss: 0.6257 - val_loss: 0.6226\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 375us/step - loss: 0.5964 - val_loss: 0.6191\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 378us/step - loss: 0.5928 - val_loss: 0.6160\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 367us/step - loss: 0.5867 - val_loss: 0.6133\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 380us/step - loss: 0.6075 - val_loss: 0.6108\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 370us/step - loss: 0.5714 - val_loss: 0.6086\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 393us/step - loss: 0.5893 - val_loss: 0.6064\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 391us/step - loss: 0.5787 - val_loss: 0.6044\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 379us/step - loss: 0.5866 - val_loss: 0.6025\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 384us/step - loss: 0.5923 - val_loss: 0.6007\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 383us/step - loss: 0.5870 - val_loss: 0.5989\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 386us/step - loss: 0.6134 - val_loss: 0.5973\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 373us/step - loss: 0.5742 - val_loss: 0.5957\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 394us/step - loss: 0.5588 - val_loss: 0.5941\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 403us/step - loss: 0.5582 - val_loss: 0.5925\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 375us/step - loss: 0.5640 - val_loss: 0.5911\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 384us/step - loss: 0.5776 - val_loss: 0.5896\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 385us/step - loss: 0.5409 - val_loss: 0.5883\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 386us/step - loss: 0.5609 - val_loss: 0.5869\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 387us/step - loss: 0.5590 - val_loss: 0.5856\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 396us/step - loss: 0.5323 - val_loss: 0.5844\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 383us/step - loss: 0.5501 - val_loss: 0.5831\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 377us/step - loss: 0.5451 - val_loss: 0.5820\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.5408 - val_loss: 0.5808\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 376us/step - loss: 0.5768 - val_loss: 0.5797\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 379us/step - loss: 0.5541 - val_loss: 0.5786\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 367us/step - loss: 0.5728 - val_loss: 0.5776\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 378us/step - loss: 0.5733 - val_loss: 0.5766\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 405us/step - loss: 0.5506 - val_loss: 0.5756\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 373us/step - loss: 0.5479 - val_loss: 0.5746\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 366us/step - loss: 0.5341 - val_loss: 0.5737\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 400us/step - loss: 0.5505 - val_loss: 0.5728\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 378us/step - loss: 0.5307 - val_loss: 0.5719\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 366us/step - loss: 0.5303 - val_loss: 0.5711\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 371us/step - loss: 0.5393 - val_loss: 0.5702\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 367us/step - loss: 0.5429 - val_loss: 0.5695\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 373us/step - loss: 0.5236 - val_loss: 0.5687\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 378us/step - loss: 0.5402 - val_loss: 0.5680\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 364us/step - loss: 0.5650 - val_loss: 0.5673\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 392us/step - loss: 0.5277 - val_loss: 0.5665\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 366us/step - loss: 0.5215 - val_loss: 0.5659\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 392us/step - loss: 0.5507 - val_loss: 0.5652\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 381us/step - loss: 0.5479 - val_loss: 0.5646\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 373us/step - loss: 0.5244 - val_loss: 0.5640\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 387us/step - loss: 0.5544 - val_loss: 0.5634\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 370us/step - loss: 0.5281 - val_loss: 0.5628\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 378us/step - loss: 0.5210 - val_loss: 0.5622\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 371us/step - loss: 0.5225 - val_loss: 0.5617\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 390us/step - loss: 0.5255 - val_loss: 0.5612\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 370us/step - loss: 0.5284 - val_loss: 0.5606\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 381us/step - loss: 0.5543 - val_loss: 0.5601\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 373us/step - loss: 0.5340 - val_loss: 0.5597\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 381us/step - loss: 0.5221 - val_loss: 0.5592\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 366us/step - loss: 0.5576 - val_loss: 0.5588\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 380us/step - loss: 0.5347 - val_loss: 0.5584\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 365us/step - loss: 0.4917 - val_loss: 0.5579\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 372us/step - loss: 0.5340 - val_loss: 0.5576\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 385us/step - loss: 0.5100 - val_loss: 0.5571\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 378us/step - loss: 0.5435 - val_loss: 0.5567\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 378us/step - loss: 0.5191 - val_loss: 0.5563\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 378us/step - loss: 0.5459 - val_loss: 0.5559\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 380us/step - loss: 0.5398 - val_loss: 0.5556\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 379us/step - loss: 0.5193 - val_loss: 0.5552\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 367us/step - loss: 0.5331 - val_loss: 0.5549\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 384us/step - loss: 0.5197 - val_loss: 0.5545\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 372us/step - loss: 0.5281 - val_loss: 0.5542\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 382us/step - loss: 0.5303 - val_loss: 0.5540\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 368us/step - loss: 0.5439 - val_loss: 0.5536\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 387us/step - loss: 0.5121 - val_loss: 0.5533\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 381us/step - loss: 0.5267 - val_loss: 0.5530\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 379us/step - loss: 0.5343 - val_loss: 0.5527\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 365us/step - loss: 0.4962 - val_loss: 0.5525\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 377us/step - loss: 0.5254 - val_loss: 0.5522\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 380us/step - loss: 0.5376 - val_loss: 0.5519\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 368us/step - loss: 0.5257 - val_loss: 0.5518\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 364us/step - loss: 0.5096 - val_loss: 0.5516\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 382us/step - loss: 0.5226 - val_loss: 0.5514\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 370us/step - loss: 0.5027 - val_loss: 0.5512\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 383us/step - loss: 0.5310 - val_loss: 0.5510\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 368us/step - loss: 0.5302 - val_loss: 0.5508\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 364us/step - loss: 0.5470 - val_loss: 0.5506\n",
      "121/121 [==============================] - 0s 205us/step - loss: 0.5514\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 565us/step - loss: 7.2635 - val_loss: 5.1807\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 378us/step - loss: 5.0953 - val_loss: 3.7726\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 375us/step - loss: 3.6926 - val_loss: 2.8266\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 380us/step - loss: 2.6963 - val_loss: 2.1860\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 368us/step - loss: 2.1809 - val_loss: 1.7488\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 377us/step - loss: 1.7357 - val_loss: 1.4488\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 359us/step - loss: 1.4041 - val_loss: 1.2410\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 368us/step - loss: 1.2176 - val_loss: 1.0966\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 377us/step - loss: 1.0588 - val_loss: 0.9956\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 368us/step - loss: 0.9706 - val_loss: 0.9244\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 374us/step - loss: 0.9526 - val_loss: 0.8730\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 363us/step - loss: 0.8934 - val_loss: 0.8359\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 381us/step - loss: 0.8559 - val_loss: 0.8086\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 366us/step - loss: 0.8166 - val_loss: 0.7879\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 368us/step - loss: 0.7753 - val_loss: 0.7715\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 385us/step - loss: 0.7564 - val_loss: 0.7584\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 369us/step - loss: 0.7544 - val_loss: 0.7481\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 394us/step - loss: 0.7382 - val_loss: 0.7392\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 372us/step - loss: 0.7190 - val_loss: 0.7312\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 383us/step - loss: 0.7363 - val_loss: 0.7241\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 369us/step - loss: 0.7043 - val_loss: 0.7179\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 363us/step - loss: 0.7012 - val_loss: 0.7120\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 383us/step - loss: 0.7201 - val_loss: 0.7066\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 389us/step - loss: 0.6974 - val_loss: 0.7012\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 381us/step - loss: 0.6806 - val_loss: 0.6961\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 389us/step - loss: 0.7080 - val_loss: 0.6913\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 387us/step - loss: 0.6809 - val_loss: 0.6869\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 371us/step - loss: 0.6712 - val_loss: 0.6825\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 374us/step - loss: 0.6795 - val_loss: 0.6782\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 370us/step - loss: 0.6896 - val_loss: 0.6743\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 376us/step - loss: 0.6646 - val_loss: 0.6702\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 361us/step - loss: 0.6374 - val_loss: 0.6664\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 375us/step - loss: 0.6713 - val_loss: 0.6626\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 380us/step - loss: 0.6789 - val_loss: 0.6592\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 371us/step - loss: 0.6744 - val_loss: 0.6558\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 362us/step - loss: 0.6477 - val_loss: 0.6524\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 368us/step - loss: 0.6188 - val_loss: 0.6492\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 370us/step - loss: 0.6308 - val_loss: 0.6460\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 369us/step - loss: 0.6219 - val_loss: 0.6429\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 375us/step - loss: 0.6505 - val_loss: 0.6400\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 373us/step - loss: 0.6403 - val_loss: 0.6371\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 361us/step - loss: 0.6162 - val_loss: 0.6343\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 373us/step - loss: 0.6356 - val_loss: 0.6316\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 364us/step - loss: 0.6226 - val_loss: 0.6290\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 368us/step - loss: 0.6209 - val_loss: 0.6264\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 373us/step - loss: 0.6159 - val_loss: 0.6239\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 360us/step - loss: 0.6107 - val_loss: 0.6216\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 367us/step - loss: 0.6098 - val_loss: 0.6193\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 373us/step - loss: 0.5855 - val_loss: 0.6171\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 364us/step - loss: 0.5744 - val_loss: 0.6149\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 370us/step - loss: 0.6033 - val_loss: 0.6128\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 368us/step - loss: 0.6168 - val_loss: 0.6108\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 360us/step - loss: 0.6005 - val_loss: 0.6088\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 370us/step - loss: 0.6297 - val_loss: 0.6069\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 363us/step - loss: 0.5698 - val_loss: 0.6050\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 386us/step - loss: 0.5903 - val_loss: 0.6032\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 367us/step - loss: 0.5747 - val_loss: 0.6014\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 371us/step - loss: 0.6129 - val_loss: 0.5997\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 387us/step - loss: 0.6031 - val_loss: 0.5981\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 364us/step - loss: 0.5959 - val_loss: 0.5965\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 389us/step - loss: 0.5749 - val_loss: 0.5949\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 367us/step - loss: 0.5836 - val_loss: 0.5934\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 407us/step - loss: 0.5977 - val_loss: 0.5920\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 378us/step - loss: 0.5739 - val_loss: 0.5905\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 364us/step - loss: 0.5760 - val_loss: 0.5892\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 393us/step - loss: 0.5602 - val_loss: 0.5878\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 379us/step - loss: 0.5908 - val_loss: 0.5866\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 388us/step - loss: 0.5594 - val_loss: 0.5853\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 388us/step - loss: 0.5726 - val_loss: 0.5841\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 372us/step - loss: 0.5616 - val_loss: 0.5829\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 400us/step - loss: 0.6008 - val_loss: 0.5818\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 375us/step - loss: 0.5689 - val_loss: 0.5807\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 373us/step - loss: 0.5822 - val_loss: 0.5796\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 371us/step - loss: 0.5730 - val_loss: 0.5786\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 384us/step - loss: 0.5753 - val_loss: 0.5776\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 369us/step - loss: 0.5608 - val_loss: 0.5766\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 399us/step - loss: 0.5392 - val_loss: 0.5756\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 371us/step - loss: 0.5623 - val_loss: 0.5747\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 385us/step - loss: 0.5623 - val_loss: 0.5738\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 376us/step - loss: 0.5659 - val_loss: 0.5729\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 363us/step - loss: 0.5587 - val_loss: 0.5721\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 382us/step - loss: 0.5376 - val_loss: 0.5713\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 365us/step - loss: 0.5468 - val_loss: 0.5705\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 374us/step - loss: 0.5774 - val_loss: 0.5697\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 373us/step - loss: 0.5637 - val_loss: 0.5690\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 370us/step - loss: 0.5540 - val_loss: 0.5682\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 388us/step - loss: 0.5655 - val_loss: 0.5675\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 372us/step - loss: 0.5572 - val_loss: 0.5669\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 371us/step - loss: 0.5483 - val_loss: 0.5662\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 370us/step - loss: 0.5543 - val_loss: 0.5656\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 390us/step - loss: 0.5637 - val_loss: 0.5649\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 374us/step - loss: 0.5378 - val_loss: 0.5643\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 364us/step - loss: 0.5605 - val_loss: 0.5638\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 379us/step - loss: 0.5562 - val_loss: 0.5632\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 375us/step - loss: 0.5529 - val_loss: 0.5626\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 384us/step - loss: 0.5516 - val_loss: 0.5621\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 365us/step - loss: 0.5345 - val_loss: 0.5615\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 365us/step - loss: 0.5727 - val_loss: 0.5610\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 379us/step - loss: 0.5651 - val_loss: 0.5605\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 365us/step - loss: 0.5428 - val_loss: 0.5601\n",
      "121/121 [==============================] - 0s 215us/step - loss: 0.5348\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 681us/step - loss: 1.9509 - val_loss: 0.6401\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.5966 - val_loss: 0.5368\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.5221 - val_loss: 0.5101\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4842 - val_loss: 0.4819\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4492 - val_loss: 0.4635\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.4617 - val_loss: 0.4494\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.4424 - val_loss: 0.4413\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.4388 - val_loss: 0.4407\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.4240 - val_loss: 0.4331\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.4190 - val_loss: 0.4227\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4058 - val_loss: 0.4185\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.4270 - val_loss: 0.4196\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.4455 - val_loss: 0.4078\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3965 - val_loss: 0.4038\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.3963 - val_loss: 0.3994\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.4170 - val_loss: 0.3985\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.4103 - val_loss: 0.3885\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.4037 - val_loss: 0.3887\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3739 - val_loss: 0.3964\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3817 - val_loss: 0.3857\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3748 - val_loss: 0.3782\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3769 - val_loss: 0.3770\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.3533 - val_loss: 0.3780\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: 0.3840 - val_loss: 0.3725\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.3751 - val_loss: 0.3711\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.3598 - val_loss: 0.3738\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.3544 - val_loss: 0.3608\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.3793 - val_loss: 0.3596\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.3550 - val_loss: 0.3534\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.3427 - val_loss: 0.3559\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.3549 - val_loss: 0.3646\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 468us/step - loss: 0.3665 - val_loss: 0.3679\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.3557 - val_loss: 0.3537\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: 0.3374 - val_loss: 0.3543\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 456us/step - loss: 0.3421 - val_loss: 0.3543\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 456us/step - loss: 0.3462 - val_loss: 0.3495\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.3523 - val_loss: 0.3400\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.3395 - val_loss: 0.3454\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.3299 - val_loss: 0.3407\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.3426 - val_loss: 0.3422\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.3265 - val_loss: 0.3449\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 456us/step - loss: 0.3284 - val_loss: 0.3432\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.3413 - val_loss: 0.3354\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.3375 - val_loss: 0.3369\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.3293 - val_loss: 0.3589\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.3212 - val_loss: 0.3367\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.3393 - val_loss: 0.3445\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.3114 - val_loss: 0.3339\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.3297 - val_loss: 0.3342\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.3249 - val_loss: 0.3316\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.3132 - val_loss: 0.3350\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3168 - val_loss: 0.3305\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.3231 - val_loss: 0.3282\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.3206 - val_loss: 0.3250\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.2998 - val_loss: 0.3325\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.3241 - val_loss: 0.3291\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3131 - val_loss: 0.3385\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.3099 - val_loss: 0.3244\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3304 - val_loss: 0.3284\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3154 - val_loss: 0.3319\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.3130 - val_loss: 0.3327\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.3045 - val_loss: 0.3222\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.3154 - val_loss: 0.3249\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3120 - val_loss: 0.3248\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.2970 - val_loss: 0.3228\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.3123 - val_loss: 0.3217\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.3069 - val_loss: 0.3208\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.3120 - val_loss: 0.3223\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.3058 - val_loss: 0.3314\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.3044 - val_loss: 0.3240\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.2975 - val_loss: 0.3184\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 461us/step - loss: 0.3042 - val_loss: 0.3282\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3212 - val_loss: 0.3306\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.3027 - val_loss: 0.3206\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.3046 - val_loss: 0.3207\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.2967 - val_loss: 0.3191\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.3028 - val_loss: 0.3226\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.2836 - val_loss: 0.3151\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.2838 - val_loss: 0.3181\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.3002 - val_loss: 0.3135\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.3045 - val_loss: 0.3159\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.2994 - val_loss: 0.3152\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.2923 - val_loss: 0.3252\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.2988 - val_loss: 0.3309\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3043 - val_loss: 0.3156\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.2849 - val_loss: 0.3195\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.2983 - val_loss: 0.3258\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: 0.3045 - val_loss: 0.3153\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.2954 - val_loss: 0.3538\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.2920 - val_loss: 0.3245\n",
      "121/121 [==============================] - 0s 236us/step - loss: 0.3136\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 2.4836 - val_loss: 0.6022\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.5490 - val_loss: 0.5254\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.4838 - val_loss: 0.4863\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.4690 - val_loss: 0.4709\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.4407 - val_loss: 0.4606\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.4487 - val_loss: 0.4414\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.4133 - val_loss: 0.4362\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.4258 - val_loss: 0.4222\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.3879 - val_loss: 0.4124\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 461us/step - loss: 0.3890 - val_loss: 0.4066\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3954 - val_loss: 0.3988\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.3913 - val_loss: 0.3948\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.3682 - val_loss: 0.3934\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3772 - val_loss: 0.3849\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.3674 - val_loss: 0.3869\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.3734 - val_loss: 0.3729\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.3670 - val_loss: 0.3730\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3578 - val_loss: 0.3716\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.3502 - val_loss: 0.3741\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 472us/step - loss: 0.3474 - val_loss: 0.3591\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3487 - val_loss: 0.3528\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.3445 - val_loss: 0.3565\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.3473 - val_loss: 0.3516\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.3533 - val_loss: 0.3488\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.3478 - val_loss: 0.3505\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.3233 - val_loss: 0.3475\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.3344 - val_loss: 0.3479\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3552 - val_loss: 0.3407\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.3307 - val_loss: 0.3378\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3180 - val_loss: 0.3495\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 461us/step - loss: 0.3280 - val_loss: 0.3341\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.3294 - val_loss: 0.3358\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.3310 - val_loss: 0.3444\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.3094 - val_loss: 0.3409\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3294 - val_loss: 0.3377\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3121 - val_loss: 0.3364\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.3067 - val_loss: 0.3247\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.3003 - val_loss: 0.3376\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: 0.3059 - val_loss: 0.3255\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: 0.3050 - val_loss: 0.3225\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.3036 - val_loss: 0.3199\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.2945 - val_loss: 0.3319\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 456us/step - loss: 0.2906 - val_loss: 0.3283\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.3195 - val_loss: 0.3191\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.2912 - val_loss: 0.3225\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.3061 - val_loss: 0.3225\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.2924 - val_loss: 0.3227\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.3146 - val_loss: 0.3204\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.2877 - val_loss: 0.3220\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.2919 - val_loss: 0.3252\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.3100 - val_loss: 0.3177\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.2911 - val_loss: 0.3195\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.2913 - val_loss: 0.3111\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.2716 - val_loss: 0.3236\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3003 - val_loss: 0.3121\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.2890 - val_loss: 0.3063\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3039 - val_loss: 0.3137\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.2827 - val_loss: 0.3107\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.2949 - val_loss: 0.3054\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.2925 - val_loss: 0.3142\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: 0.2867 - val_loss: 0.3177\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.2860 - val_loss: 0.3254\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.2804 - val_loss: 0.3102\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.2902 - val_loss: 0.3147\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.2981 - val_loss: 0.3038\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.2821 - val_loss: 0.3201\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.2744 - val_loss: 0.3054\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.2741 - val_loss: 0.3299\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.2852 - val_loss: 0.3023\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 456us/step - loss: 0.2781 - val_loss: 0.3149\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.2743 - val_loss: 0.3067\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.2720 - val_loss: 0.3145\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.2981 - val_loss: 0.3192\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.2703 - val_loss: 0.3089\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.2809 - val_loss: 0.3219\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 461us/step - loss: 0.2773 - val_loss: 0.3088\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.2811 - val_loss: 0.3020\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.2665 - val_loss: 0.3022\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.2873 - val_loss: 0.3172\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 456us/step - loss: 0.2699 - val_loss: 0.3101\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.2675 - val_loss: 0.3077\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 456us/step - loss: 0.2833 - val_loss: 0.3024\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 461us/step - loss: 0.2760 - val_loss: 0.3057\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.2747 - val_loss: 0.3174\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: 0.2664 - val_loss: 0.3100\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: 0.2698 - val_loss: 0.3004\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.2835 - val_loss: 0.3029\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.2660 - val_loss: 0.3050\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.2657 - val_loss: 0.3095\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.2637 - val_loss: 0.3077\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.2703 - val_loss: 0.3122\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.2786 - val_loss: 0.3004\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.2778 - val_loss: 0.2979\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.2829 - val_loss: 0.3015\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.2756 - val_loss: 0.3016\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.2727 - val_loss: 0.3005\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.2663 - val_loss: 0.3132\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.2750 - val_loss: 0.3066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.2671 - val_loss: 0.2987\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 456us/step - loss: 0.2810 - val_loss: 0.3020\n",
      "121/121 [==============================] - 0s 230us/step - loss: 0.3115\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 1.4768 - val_loss: 0.5754\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.5272 - val_loss: 0.5081\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.4783 - val_loss: 0.4646\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.4510 - val_loss: 0.4475\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.4396 - val_loss: 0.4350\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.4310 - val_loss: 0.4285\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.4032 - val_loss: 0.4200\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.4020 - val_loss: 0.4083\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.4093 - val_loss: 0.4004\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.3964 - val_loss: 0.3959\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.3885 - val_loss: 0.3885\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.3861 - val_loss: 0.3807\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.3910 - val_loss: 0.3812\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3717 - val_loss: 0.3727\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 461us/step - loss: 0.3789 - val_loss: 0.3678\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.3599 - val_loss: 0.3733\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.3705 - val_loss: 0.3626\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.3659 - val_loss: 0.3580\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.3672 - val_loss: 0.3715\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3992 - val_loss: 0.3556\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.3696 - val_loss: 0.3538\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3617 - val_loss: 0.3536\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 456us/step - loss: 0.3599 - val_loss: 0.3489\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.3430 - val_loss: 0.3479\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: 0.3435 - val_loss: 0.3482\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 461us/step - loss: 0.3574 - val_loss: 0.3451\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.3342 - val_loss: 0.3438\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.3301 - val_loss: 0.3409\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.3387 - val_loss: 0.3425\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.3259 - val_loss: 0.3430\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: 0.3477 - val_loss: 0.3328\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.3446 - val_loss: 0.3343\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.3208 - val_loss: 0.3332\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.3240 - val_loss: 0.3321\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.3244 - val_loss: 0.3325\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.3314 - val_loss: 0.3446\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.3153 - val_loss: 0.3319\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.3324 - val_loss: 0.3250\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 461us/step - loss: 0.3048 - val_loss: 0.3283\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.3356 - val_loss: 0.3230\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.3101 - val_loss: 0.3235\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.3308 - val_loss: 0.3225\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.3085 - val_loss: 0.3283\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.3043 - val_loss: 0.3237\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.3117 - val_loss: 0.3187\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.3002 - val_loss: 0.3176\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.2997 - val_loss: 0.3238\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 461us/step - loss: 0.3159 - val_loss: 0.3315\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 461us/step - loss: 0.3010 - val_loss: 0.3607\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.3058 - val_loss: 0.3178\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.3100 - val_loss: 0.3150\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.3034 - val_loss: 0.3150\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.3018 - val_loss: 0.3138\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: 0.2899 - val_loss: 0.3224\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 461us/step - loss: 0.3103 - val_loss: 0.3066\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.3045 - val_loss: 0.3189\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.2970 - val_loss: 0.3199\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.2983 - val_loss: 0.3187\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.2985 - val_loss: 0.3163\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.3018 - val_loss: 0.3058\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.2881 - val_loss: 0.3074\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.2960 - val_loss: 0.3049\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: 0.2956 - val_loss: 0.3054\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: 0.2791 - val_loss: 0.3069\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.2894 - val_loss: 0.3144\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.3026 - val_loss: 0.3044\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.2984 - val_loss: 0.3061\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 461us/step - loss: 0.2959 - val_loss: 0.3025\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.2799 - val_loss: 0.3001\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.2872 - val_loss: 0.3018\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 461us/step - loss: 0.2934 - val_loss: 0.3052\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 461us/step - loss: 0.2829 - val_loss: 0.3117\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.2749 - val_loss: 0.2998\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.2898 - val_loss: 0.3154\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: 0.2938 - val_loss: 0.3105\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.2936 - val_loss: 0.3032\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 465us/step - loss: 0.2821 - val_loss: 0.3148\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.2784 - val_loss: 0.3012\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.2918 - val_loss: 0.2977\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.2885 - val_loss: 0.3031\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.2826 - val_loss: 0.3087\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.2913 - val_loss: 0.3029\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.2762 - val_loss: 0.3176\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.2954 - val_loss: 0.3018\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.2744 - val_loss: 0.2981\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.2840 - val_loss: 0.2989\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.2873 - val_loss: 0.3049\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.2832 - val_loss: 0.3018\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.2932 - val_loss: 0.3018\n",
      "121/121 [==============================] - 0s 233us/step - loss: 0.3066\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 3.2549 - val_loss: 1.4795\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 1.4150 - val_loss: 1.3738\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 1.3173 - val_loss: 1.3364\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: 1.2707 - val_loss: 1.3077\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 1.2736 - val_loss: 1.2724\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 1.1939 - val_loss: 1.2218\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 1.1652 - val_loss: 1.1520\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 1.1333 - val_loss: 1.0692\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 1.0338 - val_loss: 0.9885\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: 0.9291 - val_loss: 0.9171\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: 0.8657 - val_loss: 0.8643\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: 0.8362 - val_loss: 0.8186\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 0.8230 - val_loss: 0.7822\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.7693 - val_loss: 0.7503\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.7474 - val_loss: 0.7252\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.7018 - val_loss: 0.7068\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.6987 - val_loss: 0.6932\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.6705 - val_loss: 0.6816\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.6667 - val_loss: 0.6716\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: 0.6754 - val_loss: 0.6629\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: 0.6530 - val_loss: 0.6539\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.6262 - val_loss: 0.6473\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.6428 - val_loss: 0.6382\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.6286 - val_loss: 0.6329\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.6323 - val_loss: 0.6234\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.6129 - val_loss: 0.6182\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: 0.5754 - val_loss: 0.6101\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.5965 - val_loss: 0.6032\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 437us/step - loss: 0.5884 - val_loss: 0.5974\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.5630 - val_loss: 0.5912\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.5909 - val_loss: 0.5849\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.5626 - val_loss: 0.5806\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: 0.5742 - val_loss: 0.5735\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 437us/step - loss: 0.5530 - val_loss: 0.5684\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.5743 - val_loss: 0.5631\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.5388 - val_loss: 0.5582\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.5388 - val_loss: 0.5536\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.5329 - val_loss: 0.5494\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: 0.5359 - val_loss: 0.5445\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.5228 - val_loss: 0.5403\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.5197 - val_loss: 0.5361\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.5273 - val_loss: 0.5332\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.5097 - val_loss: 0.5301\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: 0.5423 - val_loss: 0.5276\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.5031 - val_loss: 0.5260\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.5212 - val_loss: 0.5226\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.5448 - val_loss: 0.5206\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.4877 - val_loss: 0.5187\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: 0.5196 - val_loss: 0.5171\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.4970 - val_loss: 0.5148\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.5198 - val_loss: 0.5132\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: 0.5101 - val_loss: 0.5135\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.5299 - val_loss: 0.5108\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.5217 - val_loss: 0.5091\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.5356 - val_loss: 0.5094\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.4829 - val_loss: 0.5065\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.5016 - val_loss: 0.5058\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: 0.5147 - val_loss: 0.5043\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.5036 - val_loss: 0.5033\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: 0.5095 - val_loss: 0.5013\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.5043 - val_loss: 0.5004\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.4909 - val_loss: 0.4989\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 0.4872 - val_loss: 0.4981\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 437us/step - loss: 0.4980 - val_loss: 0.4972\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.4911 - val_loss: 0.4973\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 429us/step - loss: 0.4988 - val_loss: 0.4953\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.4777 - val_loss: 0.4968\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.4944 - val_loss: 0.4946\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.4900 - val_loss: 0.4925\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.5036 - val_loss: 0.4928\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.4682 - val_loss: 0.4931\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.4887 - val_loss: 0.4919\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.4906 - val_loss: 0.4892\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 437us/step - loss: 0.4721 - val_loss: 0.4889\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.4673 - val_loss: 0.4875\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.4740 - val_loss: 0.4884\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.4740 - val_loss: 0.4865\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 0.4790 - val_loss: 0.4861\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.4814 - val_loss: 0.4864\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.4762 - val_loss: 0.4844\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: 0.4703 - val_loss: 0.4846\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.4943 - val_loss: 0.4831\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.4936 - val_loss: 0.4833\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.4724 - val_loss: 0.4821\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.4872 - val_loss: 0.4811\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.4727 - val_loss: 0.4844\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: 0.4594 - val_loss: 0.4822\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.4743 - val_loss: 0.4792\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 0.4591 - val_loss: 0.4788\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.4803 - val_loss: 0.4798\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.4890 - val_loss: 0.4778\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 0.4794 - val_loss: 0.4779\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.4816 - val_loss: 0.4764\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.4859 - val_loss: 0.4767\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.4603 - val_loss: 0.4779\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.4741 - val_loss: 0.4754\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.4631 - val_loss: 0.4756\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.4729 - val_loss: 0.4740\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.4810 - val_loss: 0.4737\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.4667 - val_loss: 0.4729\n",
      "121/121 [==============================] - 0s 227us/step - loss: 0.4693\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 670us/step - loss: 4.3510 - val_loss: 2.2340\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 1.8779 - val_loss: 1.5453\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 1.4180 - val_loss: 1.4069\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: 1.3910 - val_loss: 1.3772\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 1.3185 - val_loss: 1.3697\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 1.2969 - val_loss: 1.3680\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 1.3829 - val_loss: 1.3676\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 1.3538 - val_loss: 1.3673\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: 1.3335 - val_loss: 1.3671\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 1.2899 - val_loss: 1.3670\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 437us/step - loss: 1.3370 - val_loss: 1.3669\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 437us/step - loss: 1.3488 - val_loss: 1.3672\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 1.3418 - val_loss: 1.3670\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 1.3495 - val_loss: 1.3672\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 437us/step - loss: 1.3219 - val_loss: 1.3672\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 437us/step - loss: 1.3694 - val_loss: 1.3672\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 1.3419 - val_loss: 1.3673\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 437us/step - loss: 1.3043 - val_loss: 1.3671\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 1.2877 - val_loss: 1.3670\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 1.3167 - val_loss: 1.3669\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 1.3490 - val_loss: 1.3671\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 1.2851 - val_loss: 1.3671\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 1.3326 - val_loss: 1.3671\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 1.3199 - val_loss: 1.3671\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 1.3152 - val_loss: 1.3670\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 1.3737 - val_loss: 1.3671\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 1.3665 - val_loss: 1.3671\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 1.2832 - val_loss: 1.3670\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 1.3184 - val_loss: 1.3671\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 1.3362 - val_loss: 1.3670\n",
      "121/121 [==============================] - 0s 222us/step - loss: 1.3664\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 666us/step - loss: 4.5020 - val_loss: 2.2052\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 1.9504 - val_loss: 1.5261\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 1.5081 - val_loss: 1.3964\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 1.4041 - val_loss: 1.3719\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: 1.3427 - val_loss: 1.3670\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: 1.3372 - val_loss: 1.3664\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 1.3262 - val_loss: 1.3663\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 1.3554 - val_loss: 1.3663\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 1.3921 - val_loss: 1.3663\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 1.3193 - val_loss: 1.3663\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 1.3946 - val_loss: 1.3663\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 1.3283 - val_loss: 1.3663\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 440us/step - loss: 1.3697 - val_loss: 1.3663\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 1.3691 - val_loss: 1.3663\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 437us/step - loss: 1.3202 - val_loss: 1.3663\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 1.3367 - val_loss: 1.3663\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 1.3550 - val_loss: 1.3663\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 1.3339 - val_loss: 1.3663\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 1.3719 - val_loss: 1.3663\n",
      "121/121 [==============================] - 0s 219us/step - loss: 1.3196\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 662us/step - loss: 4.0088 - val_loss: 1.4925\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 1.3563 - val_loss: 0.9515\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.8981 - val_loss: 0.7819\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: 0.7761 - val_loss: 0.7184\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: 0.6879 - val_loss: 0.6804\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.6641 - val_loss: 0.6511\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 437us/step - loss: 0.6440 - val_loss: 0.6263\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: 0.6050 - val_loss: 0.6053\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.5952 - val_loss: 0.5862\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.5923 - val_loss: 0.5701\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 456us/step - loss: 0.5608 - val_loss: 0.5545\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.5554 - val_loss: 0.5417\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.5473 - val_loss: 0.5308\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.5155 - val_loss: 0.5215\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.5221 - val_loss: 0.5125\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.5086 - val_loss: 0.5062\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.5135 - val_loss: 0.4994\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 461us/step - loss: 0.5166 - val_loss: 0.4944\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4636 - val_loss: 0.4893\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.4751 - val_loss: 0.4857\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.4496 - val_loss: 0.4804\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 456us/step - loss: 0.4773 - val_loss: 0.4766\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.4644 - val_loss: 0.4727\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.4638 - val_loss: 0.4691\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: 0.4672 - val_loss: 0.4661\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: 0.4539 - val_loss: 0.4636\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 456us/step - loss: 0.4531 - val_loss: 0.4600\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.4539 - val_loss: 0.4579\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4687 - val_loss: 0.4561\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.4405 - val_loss: 0.4530\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.4474 - val_loss: 0.4508\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.4350 - val_loss: 0.4485\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.4280 - val_loss: 0.4473\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.4312 - val_loss: 0.4441\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.4304 - val_loss: 0.4429\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.4398 - val_loss: 0.4412\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 411us/step - loss: 0.4170 - val_loss: 0.4383\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.4382 - val_loss: 0.4373\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4350 - val_loss: 0.4351\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.4199 - val_loss: 0.4337\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.4230 - val_loss: 0.4312\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.4204 - val_loss: 0.4309\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.4214 - val_loss: 0.4286\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.4140 - val_loss: 0.4270\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.4202 - val_loss: 0.4274\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.4096 - val_loss: 0.4235\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.4070 - val_loss: 0.4236\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.3947 - val_loss: 0.4209\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: 0.4349 - val_loss: 0.4208\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.4144 - val_loss: 0.4187\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.4171 - val_loss: 0.4179\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.4322 - val_loss: 0.4169\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.4046 - val_loss: 0.4162\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.4111 - val_loss: 0.4142\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.3989 - val_loss: 0.4134\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.4149 - val_loss: 0.4128\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.4007 - val_loss: 0.4128\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 412us/step - loss: 0.3920 - val_loss: 0.4099\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.3929 - val_loss: 0.4093\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.3967 - val_loss: 0.4094\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4094 - val_loss: 0.4069\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.3947 - val_loss: 0.4062\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.3910 - val_loss: 0.4051\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.4159 - val_loss: 0.4053\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.3892 - val_loss: 0.4045\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.3958 - val_loss: 0.4037\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.3888 - val_loss: 0.4026\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.3990 - val_loss: 0.4011\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.3980 - val_loss: 0.4009\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.3908 - val_loss: 0.3996\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.3873 - val_loss: 0.3996\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 413us/step - loss: 0.3841 - val_loss: 0.3983\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.3899 - val_loss: 0.3982\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.3891 - val_loss: 0.3962\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 456us/step - loss: 0.3845 - val_loss: 0.3951\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.4015 - val_loss: 0.3946\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.3944 - val_loss: 0.3956\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.3887 - val_loss: 0.3951\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.3954 - val_loss: 0.3928\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.3796 - val_loss: 0.3934\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.3803 - val_loss: 0.3921\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.3766 - val_loss: 0.3907\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.3853 - val_loss: 0.3901\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.3706 - val_loss: 0.3893\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.3782 - val_loss: 0.3885\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.3798 - val_loss: 0.3903\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.3846 - val_loss: 0.3865\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.3721 - val_loss: 0.3870\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.3788 - val_loss: 0.3866\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.3887 - val_loss: 0.3859\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.3606 - val_loss: 0.3869\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.3719 - val_loss: 0.3859\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.3796 - val_loss: 0.3845\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.3915 - val_loss: 0.3840\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.3660 - val_loss: 0.3854\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.3841 - val_loss: 0.3832\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.3743 - val_loss: 0.3830\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.3617 - val_loss: 0.3813\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.3745 - val_loss: 0.3804\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.3749 - val_loss: 0.3802\n",
      "121/121 [==============================] - 0s 210us/step - loss: 0.3753\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.4163 - val_loss: 0.8994\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 535us/step - loss: 0.8354 - val_loss: 0.7509\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.7235 - val_loss: 0.7140\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 549us/step - loss: 0.6872 - val_loss: 0.6835\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 529us/step - loss: 0.6699 - val_loss: 0.6571\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.6356 - val_loss: 0.6341\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.6045 - val_loss: 0.6125\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.5852 - val_loss: 0.5945\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 518us/step - loss: 0.5909 - val_loss: 0.5790\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.5447 - val_loss: 0.5641\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.5412 - val_loss: 0.5516\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 529us/step - loss: 0.5314 - val_loss: 0.5409\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.4934 - val_loss: 0.5300\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 461us/step - loss: 0.5020 - val_loss: 0.5203\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 591us/step - loss: 0.5014 - val_loss: 0.5150\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.4921 - val_loss: 0.5068\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.4756 - val_loss: 0.5005\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.4523 - val_loss: 0.4939\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.4911 - val_loss: 0.4886\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.4639 - val_loss: 0.4848\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.4506 - val_loss: 0.4803\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.4528 - val_loss: 0.4772\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4339 - val_loss: 0.4719\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: 0.4561 - val_loss: 0.4692\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.4438 - val_loss: 0.4660\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.4397 - val_loss: 0.4635\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 0.4323 - val_loss: 0.4606\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.4463 - val_loss: 0.4591\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.4651 - val_loss: 0.4571\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.4356 - val_loss: 0.4546\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.4498 - val_loss: 0.4518\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.4212 - val_loss: 0.4499\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: 0.4251 - val_loss: 0.4483\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.4307 - val_loss: 0.4469\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.4217 - val_loss: 0.4448\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.4155 - val_loss: 0.4429\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.4258 - val_loss: 0.4418\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4181 - val_loss: 0.4400\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.4218 - val_loss: 0.4396\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.4289 - val_loss: 0.4375\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4187 - val_loss: 0.4370\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.4193 - val_loss: 0.4356\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.4101 - val_loss: 0.4361\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.4082 - val_loss: 0.4320\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.4295 - val_loss: 0.4314\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.4107 - val_loss: 0.4307\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.4188 - val_loss: 0.4298\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: 0.4124 - val_loss: 0.4282\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.4194 - val_loss: 0.4283\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 422us/step - loss: 0.4193 - val_loss: 0.4260\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.4046 - val_loss: 0.4283\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.4262 - val_loss: 0.4243\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4180 - val_loss: 0.4232\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.3875 - val_loss: 0.4218\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4102 - val_loss: 0.4221\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.4034 - val_loss: 0.4202\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4083 - val_loss: 0.4200\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3880 - val_loss: 0.4185\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4197 - val_loss: 0.4195\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3989 - val_loss: 0.4169\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 0.4128 - val_loss: 0.4163\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.3943 - val_loss: 0.4151\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.3952 - val_loss: 0.4151\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.4036 - val_loss: 0.4145\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.4039 - val_loss: 0.4130\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.4098 - val_loss: 0.4119\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.4096 - val_loss: 0.4109\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.4085 - val_loss: 0.4107\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.4089 - val_loss: 0.4104\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.4114 - val_loss: 0.4090\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.4140 - val_loss: 0.4070\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3861 - val_loss: 0.4061\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.3872 - val_loss: 0.4069\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3963 - val_loss: 0.4054\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.3995 - val_loss: 0.4031\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.3789 - val_loss: 0.4033\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.4042 - val_loss: 0.4032\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.3967 - val_loss: 0.4023\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.3744 - val_loss: 0.4009\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.3890 - val_loss: 0.3998\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.3805 - val_loss: 0.3990\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.3643 - val_loss: 0.3989\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.3780 - val_loss: 0.3976\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.3791 - val_loss: 0.3984\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.3710 - val_loss: 0.3964\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.3669 - val_loss: 0.3970\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.3771 - val_loss: 0.3957\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.3774 - val_loss: 0.3947\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.3771 - val_loss: 0.3956\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.3883 - val_loss: 0.3931\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3712 - val_loss: 0.3924\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 551us/step - loss: 0.3938 - val_loss: 0.3941\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 542us/step - loss: 0.3789 - val_loss: 0.3912\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.3979 - val_loss: 0.3909\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.3840 - val_loss: 0.3906\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.3829 - val_loss: 0.3912\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.3767 - val_loss: 0.3888\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.3795 - val_loss: 0.3888\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.3674 - val_loss: 0.3885\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.3683 - val_loss: 0.3866\n",
      "121/121 [==============================] - 0s 212us/step - loss: 0.4005\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 4.1024 - val_loss: 0.9850\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.9271 - val_loss: 0.7861\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.7671 - val_loss: 0.7356\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.7320 - val_loss: 0.6981\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.6629 - val_loss: 0.6699\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.6570 - val_loss: 0.6428\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.6135 - val_loss: 0.6194\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.6257 - val_loss: 0.5995\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.5881 - val_loss: 0.5814\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.5552 - val_loss: 0.5656\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.5454 - val_loss: 0.5527\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.5204 - val_loss: 0.5404\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.5070 - val_loss: 0.5318\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.5283 - val_loss: 0.5202\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.5187 - val_loss: 0.5125\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.5024 - val_loss: 0.5056\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.4841 - val_loss: 0.4996\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.4903 - val_loss: 0.4947\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.4841 - val_loss: 0.4888\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.4505 - val_loss: 0.4849\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.4770 - val_loss: 0.4802\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.4653 - val_loss: 0.4772\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.4711 - val_loss: 0.4735\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.4644 - val_loss: 0.4705\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.4626 - val_loss: 0.4676\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.4362 - val_loss: 0.4652\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.4679 - val_loss: 0.4635\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 418us/step - loss: 0.4615 - val_loss: 0.4606\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.4619 - val_loss: 0.4578\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.4289 - val_loss: 0.4557\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.4463 - val_loss: 0.4538\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.4536 - val_loss: 0.4520\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.4552 - val_loss: 0.4502\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.4328 - val_loss: 0.4485\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.4434 - val_loss: 0.4465\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.4306 - val_loss: 0.4465\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.4276 - val_loss: 0.4441\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.4398 - val_loss: 0.4424\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.4495 - val_loss: 0.4414\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.4425 - val_loss: 0.4401\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.4241 - val_loss: 0.4390\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.4410 - val_loss: 0.4374\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.4216 - val_loss: 0.4361\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.4338 - val_loss: 0.4355\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.4281 - val_loss: 0.4346\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.4321 - val_loss: 0.4328\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.4300 - val_loss: 0.4311\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.4168 - val_loss: 0.4307\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.4131 - val_loss: 0.4295\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.4302 - val_loss: 0.4296\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.4371 - val_loss: 0.4287\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.4208 - val_loss: 0.4273\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.4027 - val_loss: 0.4255\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.4026 - val_loss: 0.4244\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.3982 - val_loss: 0.4253\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.4293 - val_loss: 0.4233\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.4074 - val_loss: 0.4224\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.4065 - val_loss: 0.4208\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.4245 - val_loss: 0.4199\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.4115 - val_loss: 0.4196\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.4175 - val_loss: 0.4188\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.4139 - val_loss: 0.4179\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.4033 - val_loss: 0.4166\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.4064 - val_loss: 0.4166\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.4014 - val_loss: 0.4150\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.4122 - val_loss: 0.4145\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.3964 - val_loss: 0.4133\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.4157 - val_loss: 0.4124\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.4083 - val_loss: 0.4116\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.3857 - val_loss: 0.4109\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.3929 - val_loss: 0.4125\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.3948 - val_loss: 0.4100\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.3973 - val_loss: 0.4091\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.4056 - val_loss: 0.4079\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.4080 - val_loss: 0.4075\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.3999 - val_loss: 0.4063\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.3982 - val_loss: 0.4058\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.4142 - val_loss: 0.4043\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.3984 - val_loss: 0.4042\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.3873 - val_loss: 0.4030\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.3877 - val_loss: 0.4022\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.3943 - val_loss: 0.4021\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.4023 - val_loss: 0.4013\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.3984 - val_loss: 0.4004\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.3887 - val_loss: 0.3998\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.3926 - val_loss: 0.3992\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.3851 - val_loss: 0.3982\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.3764 - val_loss: 0.3973\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.3912 - val_loss: 0.3973\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.4033 - val_loss: 0.3955\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.3733 - val_loss: 0.3956\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.3850 - val_loss: 0.3953\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.3780 - val_loss: 0.3943\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.3938 - val_loss: 0.3941\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.3833 - val_loss: 0.3932\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.3743 - val_loss: 0.3915\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.3690 - val_loss: 0.3912\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.3855 - val_loss: 0.3915\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.3877 - val_loss: 0.3891\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.3960 - val_loss: 0.3882\n",
      "121/121 [==============================] - 0s 212us/step - loss: 0.3829\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 669us/step - loss: 2.1593 - val_loss: 0.6926\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.6393 - val_loss: 0.6170\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.5850 - val_loss: 0.5731\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.5438 - val_loss: 0.5485\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.5069 - val_loss: 0.5236\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 447us/step - loss: 0.5055 - val_loss: 0.5056\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.5040 - val_loss: 0.4947\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.4680 - val_loss: 0.4878\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.4599 - val_loss: 0.4770\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.4720 - val_loss: 0.4679\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.4553 - val_loss: 0.4626\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.4524 - val_loss: 0.4579\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.4410 - val_loss: 0.4518\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4397 - val_loss: 0.4464\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4584 - val_loss: 0.4453\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4330 - val_loss: 0.4396\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.4135 - val_loss: 0.4342\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4357 - val_loss: 0.4302\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.4122 - val_loss: 0.4302\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4053 - val_loss: 0.4242\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4137 - val_loss: 0.4188\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.4218 - val_loss: 0.4168\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3882 - val_loss: 0.4147\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4069 - val_loss: 0.4136\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3928 - val_loss: 0.4093\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4028 - val_loss: 0.4044\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3977 - val_loss: 0.4082\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.3916 - val_loss: 0.3993\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4061 - val_loss: 0.3995\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3910 - val_loss: 0.3967\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.3669 - val_loss: 0.3934\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3725 - val_loss: 0.3919\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3916 - val_loss: 0.3980\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3734 - val_loss: 0.3880\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3829 - val_loss: 0.3863\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3882 - val_loss: 0.3832\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3790 - val_loss: 0.3857\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3684 - val_loss: 0.3842\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3618 - val_loss: 0.3800\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3712 - val_loss: 0.3771\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3729 - val_loss: 0.3753\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3622 - val_loss: 0.3829\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3582 - val_loss: 0.3769\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3581 - val_loss: 0.3700\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3545 - val_loss: 0.3727\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3709 - val_loss: 0.3678\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3409 - val_loss: 0.3749\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3555 - val_loss: 0.3705\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3332 - val_loss: 0.3688\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3297 - val_loss: 0.3617\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3444 - val_loss: 0.3617\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3686 - val_loss: 0.3618\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3527 - val_loss: 0.3596\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3508 - val_loss: 0.3600\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3733 - val_loss: 0.3592\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3383 - val_loss: 0.3590\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3526 - val_loss: 0.3600\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.3293 - val_loss: 0.3579\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3311 - val_loss: 0.3608\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3424 - val_loss: 0.3548\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.3287 - val_loss: 0.3556\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3309 - val_loss: 0.3507\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3362 - val_loss: 0.3522\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3328 - val_loss: 0.3480\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3369 - val_loss: 0.3503\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3358 - val_loss: 0.3481\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3368 - val_loss: 0.3479\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3310 - val_loss: 0.3542\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.3215 - val_loss: 0.3454\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3345 - val_loss: 0.3494\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3320 - val_loss: 0.3469\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3366 - val_loss: 0.3402\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3225 - val_loss: 0.3420\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3248 - val_loss: 0.3398\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3262 - val_loss: 0.3434\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3330 - val_loss: 0.3434\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3230 - val_loss: 0.3470\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3292 - val_loss: 0.3460\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3165 - val_loss: 0.3409\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.3324 - val_loss: 0.3377\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3109 - val_loss: 0.3351\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3114 - val_loss: 0.3401\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.3227 - val_loss: 0.3434\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3182 - val_loss: 0.3382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3058 - val_loss: 0.3311\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3277 - val_loss: 0.3326\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3065 - val_loss: 0.3414\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3205 - val_loss: 0.3519\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3080 - val_loss: 0.3303\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.3360 - val_loss: 0.3286\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.3069 - val_loss: 0.3298\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.3165 - val_loss: 0.3340\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.2977 - val_loss: 0.3297\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3260 - val_loss: 0.3275\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3186 - val_loss: 0.3314\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3119 - val_loss: 0.3247\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3251 - val_loss: 0.3301\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3158 - val_loss: 0.3281\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3011 - val_loss: 0.3304\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3037 - val_loss: 0.3258\n",
      "121/121 [==============================] - 0s 212us/step - loss: 0.3249\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 673us/step - loss: 2.0650 - val_loss: 0.7678\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: 0.8877 - val_loss: 0.6842\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.7285 - val_loss: 0.6074\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: 0.5869 - val_loss: 0.5641\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.5176 - val_loss: 0.5344\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.5231 - val_loss: 0.5094\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.4958 - val_loss: 0.5018\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.4559 - val_loss: 0.4813\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.4385 - val_loss: 0.4710\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.4403 - val_loss: 0.4686\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.4294 - val_loss: 0.4563\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.4418 - val_loss: 0.4514\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.4253 - val_loss: 0.4444\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.4364 - val_loss: 0.4417\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.4108 - val_loss: 0.4387\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.4224 - val_loss: 0.4364\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.4189 - val_loss: 0.4332\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.4103 - val_loss: 0.4282\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.4038 - val_loss: 0.4216\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.4150 - val_loss: 0.4197\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.3961 - val_loss: 0.4176\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4002 - val_loss: 0.4118\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3918 - val_loss: 0.4111\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.4026 - val_loss: 0.4120\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3899 - val_loss: 0.4050\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.3773 - val_loss: 0.4047\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3884 - val_loss: 0.4006\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.3846 - val_loss: 0.4000\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3928 - val_loss: 0.3959\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.3657 - val_loss: 0.3928\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3716 - val_loss: 0.3971\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3789 - val_loss: 0.3891\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3631 - val_loss: 0.3894\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.3721 - val_loss: 0.3866\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.3778 - val_loss: 0.3831\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.3818 - val_loss: 0.3791\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.3700 - val_loss: 0.3807\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3639 - val_loss: 0.3784\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.3486 - val_loss: 0.3806\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3757 - val_loss: 0.3768\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3529 - val_loss: 0.3721\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.3590 - val_loss: 0.3704\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3567 - val_loss: 0.3714\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3665 - val_loss: 0.3713\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3434 - val_loss: 0.3678\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3495 - val_loss: 0.3676\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3479 - val_loss: 0.3634\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3477 - val_loss: 0.3674\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3468 - val_loss: 0.3612\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3326 - val_loss: 0.3661\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3461 - val_loss: 0.3580\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3526 - val_loss: 0.3599\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3452 - val_loss: 0.3597\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3338 - val_loss: 0.3562\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3406 - val_loss: 0.3553\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3317 - val_loss: 0.3546\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3414 - val_loss: 0.3543\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3399 - val_loss: 0.3512\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3240 - val_loss: 0.3550\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3198 - val_loss: 0.3541\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3214 - val_loss: 0.3526\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.3378 - val_loss: 0.3505\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 450us/step - loss: 0.3233 - val_loss: 0.3476\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3267 - val_loss: 0.3480\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.3133 - val_loss: 0.3480\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3395 - val_loss: 0.3486\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3235 - val_loss: 0.3463\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3484 - val_loss: 0.3434\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3374 - val_loss: 0.3424\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3092 - val_loss: 0.3527\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3657 - val_loss: 0.3522\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3298 - val_loss: 0.3495\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.3147 - val_loss: 0.3389\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3212 - val_loss: 0.3389\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3257 - val_loss: 0.3449\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.3231 - val_loss: 0.3367\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3184 - val_loss: 0.3410\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.3224 - val_loss: 0.3372\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3193 - val_loss: 0.3440\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3139 - val_loss: 0.3356\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3123 - val_loss: 0.3376\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3227 - val_loss: 0.3415\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3313 - val_loss: 0.3365\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.3009 - val_loss: 0.3459\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.3215 - val_loss: 0.3367\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3096 - val_loss: 0.3368\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3157 - val_loss: 0.3331\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.3079 - val_loss: 0.3306\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.3160 - val_loss: 0.3294\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3090 - val_loss: 0.3283\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.2974 - val_loss: 0.3382\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3139 - val_loss: 0.3313\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3197 - val_loss: 0.3378\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.2905 - val_loss: 0.3291\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.3053 - val_loss: 0.3317\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.3114 - val_loss: 0.3375\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.2916 - val_loss: 0.3280\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.2952 - val_loss: 0.3315\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.3066 - val_loss: 0.3310\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.3116 - val_loss: 0.3265\n",
      "121/121 [==============================] - 0s 232us/step - loss: 0.3400\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 670us/step - loss: 2.4406 - val_loss: 0.6965\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.6593 - val_loss: 0.5968\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.5661 - val_loss: 0.5481\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.5358 - val_loss: 0.5208\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.4894 - val_loss: 0.5142\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.4984 - val_loss: 0.4848\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.4654 - val_loss: 0.4739\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.4566 - val_loss: 0.4669\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.4506 - val_loss: 0.4573\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.4651 - val_loss: 0.4541\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.4305 - val_loss: 0.4480\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.4277 - val_loss: 0.4404\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.4502 - val_loss: 0.4326\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.4038 - val_loss: 0.4326\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.4261 - val_loss: 0.4292\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.4166 - val_loss: 0.4212\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.4102 - val_loss: 0.4177\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.4049 - val_loss: 0.4158\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.4075 - val_loss: 0.4091\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.4051 - val_loss: 0.4083\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.3958 - val_loss: 0.4061\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3816 - val_loss: 0.4001\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3815 - val_loss: 0.4051\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.3740 - val_loss: 0.3955\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.3671 - val_loss: 0.3962\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3943 - val_loss: 0.3935\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 456us/step - loss: 0.3854 - val_loss: 0.3901\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3642 - val_loss: 0.3897\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3809 - val_loss: 0.3874\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3734 - val_loss: 0.3822\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3767 - val_loss: 0.3826\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.3730 - val_loss: 0.3801\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3744 - val_loss: 0.3787\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3668 - val_loss: 0.3758\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3572 - val_loss: 0.3761\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3606 - val_loss: 0.3751\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3669 - val_loss: 0.3756\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.3737 - val_loss: 0.3700\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3581 - val_loss: 0.3692\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3653 - val_loss: 0.3679\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 450us/step - loss: 0.3613 - val_loss: 0.3666\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3598 - val_loss: 0.3701\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.3628 - val_loss: 0.3638\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.3582 - val_loss: 0.3637\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3615 - val_loss: 0.3628\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3615 - val_loss: 0.3583\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3514 - val_loss: 0.3575\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3285 - val_loss: 0.3566\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.3338 - val_loss: 0.3563\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3615 - val_loss: 0.3582\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3445 - val_loss: 0.3559\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3452 - val_loss: 0.3539\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3310 - val_loss: 0.3519\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3379 - val_loss: 0.3503\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3347 - val_loss: 0.3496\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3475 - val_loss: 0.3490\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3308 - val_loss: 0.3471\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3396 - val_loss: 0.3467\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3433 - val_loss: 0.3446\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3343 - val_loss: 0.3457\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3403 - val_loss: 0.3462\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3437 - val_loss: 0.3494\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3438 - val_loss: 0.3410\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3393 - val_loss: 0.3411\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3314 - val_loss: 0.3450\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3188 - val_loss: 0.3425\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3195 - val_loss: 0.3409\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3287 - val_loss: 0.3375\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3269 - val_loss: 0.3368\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3307 - val_loss: 0.3411\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3252 - val_loss: 0.3347\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3237 - val_loss: 0.3363\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3250 - val_loss: 0.3345\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3272 - val_loss: 0.3354\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3107 - val_loss: 0.3401\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3154 - val_loss: 0.3340\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3144 - val_loss: 0.3314\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3011 - val_loss: 0.3300\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3145 - val_loss: 0.3311\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3139 - val_loss: 0.3290\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3252 - val_loss: 0.3293\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.3312 - val_loss: 0.3301\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3197 - val_loss: 0.3302\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3266 - val_loss: 0.3284\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3092 - val_loss: 0.3260\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3238 - val_loss: 0.3248\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.2948 - val_loss: 0.3311\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.3141 - val_loss: 0.3265\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.3161 - val_loss: 0.3358\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3215 - val_loss: 0.3287\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.2901 - val_loss: 0.3229\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3023 - val_loss: 0.3361\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.3141 - val_loss: 0.3220\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.3044 - val_loss: 0.3224\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.3148 - val_loss: 0.3272\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3003 - val_loss: 0.3299\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3016 - val_loss: 0.3233\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.2915 - val_loss: 0.3228\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3136 - val_loss: 0.3225\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3035 - val_loss: 0.3284\n",
      "121/121 [==============================] - 0s 218us/step - loss: 0.3441\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5180 - val_loss: 0.6007\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5727 - val_loss: 0.4966\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.4867 - val_loss: 0.4646\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 551us/step - loss: 0.4522 - val_loss: 0.4481\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.4304 - val_loss: 0.4415\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.4570 - val_loss: 0.4327\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: 0.4304 - val_loss: 0.4269\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.4259 - val_loss: 0.4178\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.4119 - val_loss: 0.4247\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.4094 - val_loss: 0.4120\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: 0.4082 - val_loss: 0.4029\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: 0.4108 - val_loss: 0.3986\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4124 - val_loss: 0.4000\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3902 - val_loss: 0.3940\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.3780 - val_loss: 0.3892\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.4011 - val_loss: 0.3875\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: 0.3820 - val_loss: 0.3790\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.4066 - val_loss: 0.3863\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 432us/step - loss: 0.3665 - val_loss: 0.3803\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 0.3833 - val_loss: 0.3728\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.3702 - val_loss: 0.3727\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.3912 - val_loss: 0.3710\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.3674 - val_loss: 0.3713\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.3335 - val_loss: 0.3782\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: 0.3637 - val_loss: 0.3689\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3613 - val_loss: 0.3595\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 0.3646 - val_loss: 0.3573\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.3551 - val_loss: 0.3599\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 571us/step - loss: 0.3646 - val_loss: 0.3604\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 542us/step - loss: 0.3562 - val_loss: 0.3539\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.3538 - val_loss: 0.3560\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3560 - val_loss: 0.3611\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.3395 - val_loss: 0.3567\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.3490 - val_loss: 0.3535\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.3594 - val_loss: 0.3527\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.3187 - val_loss: 0.3634\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 456us/step - loss: 0.3420 - val_loss: 0.3585\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.3319 - val_loss: 0.3485\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.3284 - val_loss: 0.3466\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.3563 - val_loss: 0.3488\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.3163 - val_loss: 0.3429\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.3231 - val_loss: 0.3403\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 541us/step - loss: 0.3286 - val_loss: 0.3449\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 524us/step - loss: 0.3236 - val_loss: 0.3499\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 456us/step - loss: 0.3264 - val_loss: 0.3432\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.3345 - val_loss: 0.3400\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.3293 - val_loss: 0.3369\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3356 - val_loss: 0.3347\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3177 - val_loss: 0.3351\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 583us/step - loss: 0.3272 - val_loss: 0.3429\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 554us/step - loss: 0.3311 - val_loss: 0.3472\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.3400 - val_loss: 0.3313\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.3073 - val_loss: 0.3326\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.3430 - val_loss: 0.3294\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.3341 - val_loss: 0.3362\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.3293 - val_loss: 0.3267\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.3271 - val_loss: 0.3296\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.3368 - val_loss: 0.3253\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.3085 - val_loss: 0.3275\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: 0.3210 - val_loss: 0.3409\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.3052 - val_loss: 0.3401\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.3174 - val_loss: 0.3326\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.3327 - val_loss: 0.3409\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.3150 - val_loss: 0.3365\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.3203 - val_loss: 0.3245\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.3227 - val_loss: 0.3230\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.3290 - val_loss: 0.3360\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.3235 - val_loss: 0.3154\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.3120 - val_loss: 0.3322\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.3159 - val_loss: 0.3192\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.3166 - val_loss: 0.3225\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.3088 - val_loss: 0.3277\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.3000 - val_loss: 0.3249\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.3057 - val_loss: 0.3204\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.2962 - val_loss: 0.3233\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.3054 - val_loss: 0.3181\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.3089 - val_loss: 0.3277\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.3116 - val_loss: 0.3350\n",
      "121/121 [==============================] - 0s 216us/step - loss: 0.3252\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 642us/step - loss: 1.4819 - val_loss: 0.5729\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.6356 - val_loss: 0.5140\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.5435 - val_loss: 0.4908\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.4640 - val_loss: 0.4808\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.5105 - val_loss: 0.4706\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: 0.4329 - val_loss: 0.4573\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.4392 - val_loss: 0.4431\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: 0.4056 - val_loss: 0.4356\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.4157 - val_loss: 0.4362\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.4331 - val_loss: 0.4217\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.3913 - val_loss: 0.4207\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.3988 - val_loss: 0.4141\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.4008 - val_loss: 0.4084\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.4011 - val_loss: 0.4013\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.3876 - val_loss: 0.4058\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.3974 - val_loss: 0.4003\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.3700 - val_loss: 0.3931\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.3750 - val_loss: 0.3923\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 431us/step - loss: 0.3841 - val_loss: 0.3848\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 550us/step - loss: 0.3666 - val_loss: 0.3923\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.3510 - val_loss: 0.3817\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3659 - val_loss: 0.3825\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.3632 - val_loss: 0.3742\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.3614 - val_loss: 0.3785\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3606 - val_loss: 0.3665\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.3637 - val_loss: 0.3645\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 670us/step - loss: 0.3622 - val_loss: 0.3711\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3500 - val_loss: 0.3664\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 598us/step - loss: 0.3440 - val_loss: 0.3639\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 735us/step - loss: 0.3445 - val_loss: 0.3588\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 694us/step - loss: 0.3392 - val_loss: 0.3685\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.3275 - val_loss: 0.3573\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 549us/step - loss: 0.3411 - val_loss: 0.3647\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 559us/step - loss: 0.3385 - val_loss: 0.3534\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.3389 - val_loss: 0.3518\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 616us/step - loss: 0.3345 - val_loss: 0.3443\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 612us/step - loss: 0.3311 - val_loss: 0.3437\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 518us/step - loss: 0.3482 - val_loss: 0.3467\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 541us/step - loss: 0.3297 - val_loss: 0.3401\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 641us/step - loss: 0.3398 - val_loss: 0.3458\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.3262 - val_loss: 0.3415\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.3315 - val_loss: 0.3390\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.3312 - val_loss: 0.3400\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3582 - val_loss: 0.3355\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.3410 - val_loss: 0.3318\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 505us/step - loss: 0.3104 - val_loss: 0.3503\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.3145 - val_loss: 0.3441\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.3248 - val_loss: 0.3302\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.3306 - val_loss: 0.3451\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.3096 - val_loss: 0.3348\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.3187 - val_loss: 0.3281\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 561us/step - loss: 0.2971 - val_loss: 0.3268\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.3154 - val_loss: 0.3396\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 546us/step - loss: 0.3101 - val_loss: 0.3429\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.3227 - val_loss: 0.3267\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.3101 - val_loss: 0.3227\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 565us/step - loss: 0.3055 - val_loss: 0.3280\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.2970 - val_loss: 0.3193\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.2933 - val_loss: 0.3309\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.3146 - val_loss: 0.3279\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.3123 - val_loss: 0.3258\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.3018 - val_loss: 0.3266\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 557us/step - loss: 0.2978 - val_loss: 0.3214\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3043 - val_loss: 0.3160\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.2928 - val_loss: 0.3187\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.3155 - val_loss: 0.3187\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.2821 - val_loss: 0.3242\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.2947 - val_loss: 0.3240\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.2832 - val_loss: 0.3156\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 605us/step - loss: 0.2993 - val_loss: 0.3295\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 516us/step - loss: 0.2865 - val_loss: 0.3138\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.2972 - val_loss: 0.3135\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 998us/step - loss: 0.2818 - val_loss: 0.3174\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.2858 - val_loss: 0.3217\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 685us/step - loss: 0.3026 - val_loss: 0.3116\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.2927 - val_loss: 0.3100\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 656us/step - loss: 0.2900 - val_loss: 0.3279\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 554us/step - loss: 0.3025 - val_loss: 0.3224\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 553us/step - loss: 0.2848 - val_loss: 0.3304\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 562us/step - loss: 0.2857 - val_loss: 0.3220\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.2878 - val_loss: 0.3128\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2859 - val_loss: 0.3170\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.2959 - val_loss: 0.3109\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.2826 - val_loss: 0.3144\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.2891 - val_loss: 0.3121\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 613us/step - loss: 0.2873 - val_loss: 0.3143\n",
      "121/121 [==============================] - 0s 464us/step - loss: 0.3245\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 914us/step - loss: 1.7957 - val_loss: 0.5900\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 561us/step - loss: 0.5600 - val_loss: 0.5263\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.5072 - val_loss: 0.4925\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4811 - val_loss: 0.4743\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.4817 - val_loss: 0.4647\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.4433 - val_loss: 0.4510\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.4545 - val_loss: 0.4502\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 576us/step - loss: 0.4503 - val_loss: 0.4443\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.4217 - val_loss: 0.4287\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.3988 - val_loss: 0.4330\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 492us/step - loss: 0.4131 - val_loss: 0.4229\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 580us/step - loss: 0.3940 - val_loss: 0.4149\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 612us/step - loss: 0.4130 - val_loss: 0.4299\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 543us/step - loss: 0.4170 - val_loss: 0.4280\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 673us/step - loss: 0.4173 - val_loss: 0.4036\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 578us/step - loss: 0.4084 - val_loss: 0.3999\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.4130 - val_loss: 0.3969\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4107 - val_loss: 0.3912\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.3970 - val_loss: 0.3856\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.3779 - val_loss: 0.3829\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.3750 - val_loss: 0.3784\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3779 - val_loss: 0.3776\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.3826 - val_loss: 0.3730\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.3696 - val_loss: 0.3691\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.3587 - val_loss: 0.3720\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3558 - val_loss: 0.3654\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.3522 - val_loss: 0.3636\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.3471 - val_loss: 0.3622\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.3667 - val_loss: 0.3602\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.3407 - val_loss: 0.3591\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.3600 - val_loss: 0.3606\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3482 - val_loss: 0.3501\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.3510 - val_loss: 0.3504\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.3471 - val_loss: 0.3557\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.3376 - val_loss: 0.3494\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.3496 - val_loss: 0.3603\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.3321 - val_loss: 0.3468\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.3311 - val_loss: 0.3450\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.3355 - val_loss: 0.3698\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.3270 - val_loss: 0.3479\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.3410 - val_loss: 0.3416\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.3361 - val_loss: 0.3387\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.3344 - val_loss: 0.3464\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.3275 - val_loss: 0.3484\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.3520 - val_loss: 0.3380\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.3242 - val_loss: 0.3386\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.3296 - val_loss: 0.3347\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.3302 - val_loss: 0.3365\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.3278 - val_loss: 0.3334\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.3332 - val_loss: 0.3396\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.3178 - val_loss: 0.3511\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.3317 - val_loss: 0.3384\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.3185 - val_loss: 0.3304\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.3033 - val_loss: 0.3766\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.3214 - val_loss: 0.3303\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.3222 - val_loss: 0.3306\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: 0.3156 - val_loss: 0.3314\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3103 - val_loss: 0.3362\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.3089 - val_loss: 0.3353\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 514us/step - loss: 0.3034 - val_loss: 0.3311\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.3193 - val_loss: 0.3351\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 461us/step - loss: 0.3064 - val_loss: 0.3299\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3164 - val_loss: 0.3259\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.3119 - val_loss: 0.3216\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.3045 - val_loss: 0.3202\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.3098 - val_loss: 0.3306\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 437us/step - loss: 0.3254 - val_loss: 0.3257\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.3073 - val_loss: 0.3307\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.3101 - val_loss: 0.3268\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.3190 - val_loss: 0.3224\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.3108 - val_loss: 0.3201\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: 0.3099 - val_loss: 0.3169\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.3228 - val_loss: 0.3228\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.3170 - val_loss: 0.3318\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.3176 - val_loss: 0.3306\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.3018 - val_loss: 0.3195\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.3076 - val_loss: 0.3269\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.3061 - val_loss: 0.3203\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.2989 - val_loss: 0.3183\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.3106 - val_loss: 0.3183\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.3148 - val_loss: 0.3124\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.3161 - val_loss: 0.3282\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.2964 - val_loss: 0.3264\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.3019 - val_loss: 0.3322\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.2955 - val_loss: 0.3547\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.3175 - val_loss: 0.3118\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.3011 - val_loss: 0.3154\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2928 - val_loss: 0.3136\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.3042 - val_loss: 0.3258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.3011 - val_loss: 0.3166\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.2950 - val_loss: 0.3178\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.3032 - val_loss: 0.3130\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.3233 - val_loss: 0.3189\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.2988 - val_loss: 0.3101\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.2828 - val_loss: 0.3093\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.3042 - val_loss: 0.3228\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.3023 - val_loss: 0.3222\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.2960 - val_loss: 0.3099\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.2980 - val_loss: 0.3128\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.2956 - val_loss: 0.3126\n",
      "121/121 [==============================] - 0s 209us/step - loss: 0.3256\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 728us/step - loss: 1.1874 - val_loss: 0.5554\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.5223 - val_loss: 0.4695\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.4675 - val_loss: 0.4360\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 504us/step - loss: 0.4234 - val_loss: 0.4138\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 537us/step - loss: 0.4063 - val_loss: 0.4260\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.3977 - val_loss: 0.4031\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 565us/step - loss: 0.3798 - val_loss: 0.3836\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 539us/step - loss: 0.3922 - val_loss: 0.3772\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 551us/step - loss: 0.3610 - val_loss: 0.3688\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 554us/step - loss: 0.3630 - val_loss: 0.3722\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 530us/step - loss: 0.3722 - val_loss: 0.3690\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 539us/step - loss: 0.3694 - val_loss: 0.3683\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.3509 - val_loss: 0.3849\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.3432 - val_loss: 0.3589\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 533us/step - loss: 0.3428 - val_loss: 0.3674\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.3496 - val_loss: 0.3453\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 517us/step - loss: 0.3528 - val_loss: 0.3530\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.3530 - val_loss: 0.3566\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.3365 - val_loss: 0.3505\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 520us/step - loss: 0.3378 - val_loss: 0.3715\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 522us/step - loss: 0.3400 - val_loss: 0.3355\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.3363 - val_loss: 0.3396\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.3118 - val_loss: 0.3302\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.3367 - val_loss: 0.3947\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.3060 - val_loss: 0.3442\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 504us/step - loss: 0.3232 - val_loss: 0.3371\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 588us/step - loss: 0.3108 - val_loss: 0.3474\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.2923 - val_loss: 0.3280\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.2972 - val_loss: 0.3693\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.3352 - val_loss: 0.3405\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.2996 - val_loss: 0.3169\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 549us/step - loss: 0.2978 - val_loss: 0.3497\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.3252 - val_loss: 0.3176\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 590us/step - loss: 0.3026 - val_loss: 0.3232\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 636us/step - loss: 0.3146 - val_loss: 0.3379\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.2947 - val_loss: 0.4142\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 520us/step - loss: 0.3034 - val_loss: 0.3431\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 541us/step - loss: 0.3155 - val_loss: 0.3213\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 609us/step - loss: 0.3049 - val_loss: 0.3117\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 535us/step - loss: 0.3057 - val_loss: 0.3439\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.2907 - val_loss: 0.3204\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.3040 - val_loss: 0.3103\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.3040 - val_loss: 0.3125\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.3092 - val_loss: 0.3331\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.2708 - val_loss: 0.3321\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 516us/step - loss: 0.2833 - val_loss: 0.3583\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.2943 - val_loss: 0.3064\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.2861 - val_loss: 0.3098\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.2856 - val_loss: 0.3490\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.2734 - val_loss: 0.3367\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.2887 - val_loss: 0.3153\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.2950 - val_loss: 0.3142\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.2908 - val_loss: 0.3080\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.2927 - val_loss: 0.3173\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.2784 - val_loss: 0.3302\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.2936 - val_loss: 0.3149\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.2908 - val_loss: 0.3053\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.2801 - val_loss: 0.3275\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.2781 - val_loss: 0.3172\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.2681 - val_loss: 0.3142\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.2793 - val_loss: 0.3218\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.2619 - val_loss: 0.3081\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.2844 - val_loss: 0.3336\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.2712 - val_loss: 0.3269\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.2715 - val_loss: 0.3079\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.2877 - val_loss: 0.3273\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.2671 - val_loss: 0.3142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 0s 227us/step - loss: 0.3158\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 722us/step - loss: 1.2921 - val_loss: 0.5395\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.5161 - val_loss: 0.4782\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.4558 - val_loss: 0.4505\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.4413 - val_loss: 0.4312\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.4460 - val_loss: 0.4209\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.4156 - val_loss: 0.4106\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.4197 - val_loss: 0.4154\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.3857 - val_loss: 0.4005\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.3600 - val_loss: 0.3920\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 518us/step - loss: 0.3663 - val_loss: 0.3779\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 505us/step - loss: 0.3649 - val_loss: 0.3847\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.3702 - val_loss: 0.3903\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.3523 - val_loss: 0.3664\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.3561 - val_loss: 0.3639\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.3550 - val_loss: 0.3575\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.3435 - val_loss: 0.3491\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.3259 - val_loss: 0.3420\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.3424 - val_loss: 0.3571\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 517us/step - loss: 0.3378 - val_loss: 0.3768\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.3175 - val_loss: 0.3812\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.3075 - val_loss: 0.3419\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.3085 - val_loss: 0.3299\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.3166 - val_loss: 0.3295\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.3356 - val_loss: 0.3250\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.2984 - val_loss: 0.3394\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.3381 - val_loss: 0.3302\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.3117 - val_loss: 0.3231\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.3027 - val_loss: 0.3192\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.2905 - val_loss: 0.3170\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.3012 - val_loss: 0.3187\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.2944 - val_loss: 0.3232\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.2953 - val_loss: 0.3553\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.3058 - val_loss: 0.3316\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.2909 - val_loss: 0.3150\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.3023 - val_loss: 0.3231\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.2797 - val_loss: 0.3191\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.2835 - val_loss: 0.3090\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 571us/step - loss: 0.2796 - val_loss: 0.3105\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.2963 - val_loss: 0.3123\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.2820 - val_loss: 0.2974\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.2930 - val_loss: 0.3107\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.2827 - val_loss: 0.3186\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 620us/step - loss: 0.2733 - val_loss: 0.3064\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.2885 - val_loss: 0.3263\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.3309 - val_loss: 0.3086\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.2825 - val_loss: 0.3067\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.3000 - val_loss: 0.3202\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.2753 - val_loss: 0.3123\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.2717 - val_loss: 0.3235\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.2670 - val_loss: 0.2985\n",
      "121/121 [==============================] - 0s 225us/step - loss: 0.3149\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 727us/step - loss: 2.1073 - val_loss: 0.5457\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.8635 - val_loss: 0.5661\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 504us/step - loss: 0.5031 - val_loss: 0.4627\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.4198 - val_loss: 0.4199\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.4227 - val_loss: 0.4023\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 504us/step - loss: 0.4079 - val_loss: 0.3929\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.3947 - val_loss: 0.3757\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.3570 - val_loss: 0.3577\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.3635 - val_loss: 0.3480\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.3450 - val_loss: 0.3446\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.3416 - val_loss: 0.3365\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.3357 - val_loss: 0.3378\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.3268 - val_loss: 0.3496\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.3207 - val_loss: 0.3265\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.3300 - val_loss: 0.3211\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.3301 - val_loss: 0.3245\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.3072 - val_loss: 0.3262\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.3352 - val_loss: 0.3115\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.3027 - val_loss: 0.3157\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.3071 - val_loss: 0.3213\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.2827 - val_loss: 0.3106\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.2942 - val_loss: 0.3212\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.2943 - val_loss: 0.3008\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.3088 - val_loss: 0.3051\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.3077 - val_loss: 0.3446\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.2973 - val_loss: 0.2996\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.2862 - val_loss: 0.3063\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 499us/step - loss: 0.2972 - val_loss: 0.3146\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.2995 - val_loss: 0.3050\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.2898 - val_loss: 0.3040\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.2802 - val_loss: 0.2936\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.2852 - val_loss: 0.2992\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.2924 - val_loss: 0.3116\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.2794 - val_loss: 0.3081\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.2943 - val_loss: 0.2983\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.2915 - val_loss: 0.3005\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.2895 - val_loss: 0.2918\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.2660 - val_loss: 0.3007\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.2965 - val_loss: 0.2966\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.2838 - val_loss: 0.3155\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.2705 - val_loss: 0.2855\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.2714 - val_loss: 0.3130\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.2647 - val_loss: 0.2981\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.2780 - val_loss: 0.3074\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.2738 - val_loss: 0.2946\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.2722 - val_loss: 0.2901\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.2761 - val_loss: 0.2907\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.2869 - val_loss: 0.3066\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.2685 - val_loss: 0.3204\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.2751 - val_loss: 0.2849\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.2737 - val_loss: 0.2831\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.2712 - val_loss: 0.2916\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.2653 - val_loss: 0.3004\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.2673 - val_loss: 0.2844\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.2673 - val_loss: 0.3016\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.2608 - val_loss: 0.2882\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.2598 - val_loss: 0.2990\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.2620 - val_loss: 0.2890\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.2616 - val_loss: 0.2892\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.2606 - val_loss: 0.2841\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.2660 - val_loss: 0.3007\n",
      "121/121 [==============================] - 0s 234us/step - loss: 0.3123\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 605us/step - loss: 3.1434 - val_loss: 0.6129\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 363us/step - loss: 0.5674 - val_loss: 0.5686\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 389us/step - loss: 0.5459 - val_loss: 0.5596\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 357us/step - loss: 0.5381 - val_loss: 0.5544\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 377us/step - loss: 0.5442 - val_loss: 0.5508\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 359us/step - loss: 0.5519 - val_loss: 0.5476\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 351us/step - loss: 0.5299 - val_loss: 0.5457\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 377us/step - loss: 0.5401 - val_loss: 0.5438\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 358us/step - loss: 0.5288 - val_loss: 0.5433\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 350us/step - loss: 0.5418 - val_loss: 0.5432\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 348us/step - loss: 0.5498 - val_loss: 0.5418\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 343us/step - loss: 0.5519 - val_loss: 0.5411\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 348us/step - loss: 0.5231 - val_loss: 0.5419\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 343us/step - loss: 0.5224 - val_loss: 0.5406\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 345us/step - loss: 0.5085 - val_loss: 0.5398\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 351us/step - loss: 0.5255 - val_loss: 0.5436\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 349us/step - loss: 0.5329 - val_loss: 0.5409\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 343us/step - loss: 0.5298 - val_loss: 0.5405\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 346us/step - loss: 0.5218 - val_loss: 0.5418\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 347us/step - loss: 0.5376 - val_loss: 0.5409\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 347us/step - loss: 0.5195 - val_loss: 0.5420\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 348us/step - loss: 0.5324 - val_loss: 0.5399\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 350us/step - loss: 0.5551 - val_loss: 0.5407\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 350us/step - loss: 0.5212 - val_loss: 0.5404\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 348us/step - loss: 0.5254 - val_loss: 0.5420\n",
      "121/121 [==============================] - 0s 187us/step - loss: 0.5233\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 541us/step - loss: 3.3801 - val_loss: 0.6123\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 356us/step - loss: 0.5777 - val_loss: 0.5836\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.5678 - val_loss: 0.5597\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 363us/step - loss: 0.5484 - val_loss: 0.5575\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 350us/step - loss: 0.5629 - val_loss: 0.5501\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 351us/step - loss: 0.5197 - val_loss: 0.5750\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 352us/step - loss: 0.5498 - val_loss: 0.5468\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 349us/step - loss: 0.5180 - val_loss: 0.5487\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 349us/step - loss: 0.5505 - val_loss: 0.5469\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 349us/step - loss: 0.5031 - val_loss: 0.5641\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 349us/step - loss: 0.5307 - val_loss: 0.5470\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 347us/step - loss: 0.5216 - val_loss: 0.5567\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 346us/step - loss: 0.5088 - val_loss: 0.5640\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 344us/step - loss: 0.5323 - val_loss: 0.5889\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 343us/step - loss: 0.5264 - val_loss: 0.5459\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 346us/step - loss: 0.5406 - val_loss: 0.5402\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 351us/step - loss: 0.4991 - val_loss: 0.5557\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 349us/step - loss: 0.5533 - val_loss: 0.5380\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 348us/step - loss: 0.5415 - val_loss: 0.5477\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 349us/step - loss: 0.5198 - val_loss: 0.5744\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 343us/step - loss: 0.5330 - val_loss: 0.5448\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 350us/step - loss: 0.5112 - val_loss: 0.5383\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 343us/step - loss: 0.5397 - val_loss: 0.5479\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 344us/step - loss: 0.5567 - val_loss: 0.5391\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 349us/step - loss: 0.5377 - val_loss: 0.5495\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 342us/step - loss: 0.5418 - val_loss: 0.5477\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 347us/step - loss: 0.5388 - val_loss: 0.5489\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 344us/step - loss: 0.5289 - val_loss: 0.5510\n",
      "121/121 [==============================] - 0s 188us/step - loss: 0.5617\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 3.7141 - val_loss: 0.8092\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 345us/step - loss: 0.7509 - val_loss: 0.6888\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 344us/step - loss: 0.6668 - val_loss: 0.6426\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 350us/step - loss: 0.6091 - val_loss: 0.6162\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 350us/step - loss: 0.5965 - val_loss: 0.5988\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 353us/step - loss: 0.5775 - val_loss: 0.5840\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 350us/step - loss: 0.5677 - val_loss: 0.5714\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 347us/step - loss: 0.5381 - val_loss: 0.5705\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 350us/step - loss: 0.5437 - val_loss: 0.5595\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 351us/step - loss: 0.5813 - val_loss: 0.5537\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 350us/step - loss: 0.5519 - val_loss: 0.6059\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 350us/step - loss: 0.5557 - val_loss: 0.5471\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 344us/step - loss: 0.5180 - val_loss: 0.5502\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 354us/step - loss: 0.5512 - val_loss: 0.5479\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 343us/step - loss: 0.5149 - val_loss: 0.5639\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 347us/step - loss: 0.5406 - val_loss: 0.5557\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 344us/step - loss: 0.5501 - val_loss: 0.5442\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 342us/step - loss: 0.5553 - val_loss: 0.5452\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 341us/step - loss: 0.5350 - val_loss: 0.5693\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 342us/step - loss: 0.5323 - val_loss: 0.5410\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 349us/step - loss: 0.5390 - val_loss: 0.5453\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 349us/step - loss: 0.5486 - val_loss: 0.5423\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 345us/step - loss: 0.5434 - val_loss: 0.5544\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 356us/step - loss: 0.5528 - val_loss: 0.5646\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 343us/step - loss: 0.5518 - val_loss: 0.5422\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 340us/step - loss: 0.5264 - val_loss: 0.5470\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 341us/step - loss: 0.5378 - val_loss: 0.5421\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 348us/step - loss: 0.5639 - val_loss: 0.5399\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 339us/step - loss: 0.5601 - val_loss: 0.5540\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 348us/step - loss: 0.5601 - val_loss: 0.5807\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 348us/step - loss: 0.5558 - val_loss: 0.5401\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 348us/step - loss: 0.5457 - val_loss: 0.5430\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 348us/step - loss: 0.5514 - val_loss: 0.5415\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 343us/step - loss: 0.5481 - val_loss: 0.5833\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 342us/step - loss: 0.5686 - val_loss: 0.5478\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 348us/step - loss: 0.5183 - val_loss: 0.5585\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 343us/step - loss: 0.5508 - val_loss: 0.5405\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 348us/step - loss: 0.5594 - val_loss: 0.5559\n",
      "121/121 [==============================] - 0s 186us/step - loss: 0.5239\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x110392f10>, as the constructor either does not set or modifies parameter learning_rate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-44c4c24bfc53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrnd_search_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distribs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m rnd_search_cv.fit(X_train, y_train, epochs=100,\n\u001b[0m\u001b[1;32m      3\u001b[0m                   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
      "\u001b[0;32m~/miniforge3/envs/atf24/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/atf24/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    874\u001b[0m             \u001b[0;31m# we clone again after setting params in case some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0;31m# of the params are estimators as well.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0m\u001b[1;32m    877\u001b[0m                 **self.best_params_))\n\u001b[1;32m    878\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/atf24/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/atf24/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mparam2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam1\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparam2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0m\u001b[1;32m     86\u001b[0m                                \u001b[0;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                                (estimator, name))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x110392f10>, as the constructor either does not set or modifies parameter learning_rate"
     ]
    }
   ],
   "source": [
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-bundle",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-pitch",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = rnd_search_Cvv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-mozambique",
   "metadata": {},
   "source": [
    "## 5.1 Hidden Layer 수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-daughter",
   "metadata": {},
   "source": [
    "* 이론적으로 은닉층이 하나인 다층 퍼셉트론이더라도 뉴런 갯수가 충분하면 아주 복잡한 함수도 모델링이 가능\n",
    "* 하지만 복잡한 문제에서는 심층 신경망이 얕은 신경망보다 파라미터 효율성이 훨씬 좋음\n",
    "    * 심층 신경망은 복잡한 함수를 모델링하는 데 얕은 신경망보다 훨씬 적은 수의 뉴런을 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-salad",
   "metadata": {},
   "source": [
    "## 5.2 Neuron 갯수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-mirror",
   "metadata": {},
   "source": [
    "* Input, Output Layerd의 Neuron 갯수는 해당 작업에 필요한 입력과 출력의 형태에 따라 결정\n",
    "* 은닉층의 구성 방식은 일반적으로 각 층의 Neuron을 점점 줄여서 깔때기처럼 구성\n",
    "    * 저수준의 많은 특성이 고수준의 적은 특성으로 합쳐질 수 있기 때문\n",
    "* layer의 수와 마찬가지로 네트워크가 과대적합이 시작되기 전까지 점진적으로 Neuron 수를 늘릴 수 있음\n",
    "    * 하지만 실전에서는 필요한 것보다 더 많은 Layer와 Neuron을 가진 모델을 선택하고, 그런 다음 과대적합되지 않도록 조기 종료나 규제 기법을 사용하는 것이 간단하고 효과적\n",
    "* 일반적으로 Neuron의 수보다 Layer의 수를 늘리는 쪽이 이득이 많음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-chest",
   "metadata": {},
   "source": [
    "## 5.3 Learning Rate, Batch Size and Others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-refund",
   "metadata": {},
   "source": [
    "### Learning Rate\n",
    "* 좋은 학습률을 찾는 한 가지 방법은 매우 낮은 학습률(eg. $10^{-5}$)에서 시작해서 점직전으로 매우 큰 학습률(eg. $10$)까지 수백 번 반복하여 학습하는 것\n",
    "\n",
    "### Optimizer\n",
    "* 고전적인 평범한 미니배치 경사 하강법보다 더 좋은 옵티마이저를 선택하는 것도 매우 중요\n",
    "\n",
    "### Batch Size\n",
    "* 배치 크기는 모델 성능과 훈련 시간에 큰 영향을 미칠 수 있음\n",
    "* GPU 램에 맞는 가장 큰 배치 크기를 사용하라고 권장\n",
    "    * 하지만 실전에서 큰 배치를 사용하면 특히 훈련 초기에 종종 불안정하게 훈련이 됨\n",
    "* 2 ~ 32까지의 작은 배치를 사용하는 것을 권장하는 논문도 있고, 학습률 예열 같은 다양한 기법을 사용함녀 매우 큰 배치 크기(8,192)를 사용할 수 있다는 논문도 있음\n",
    "* 큰 배치 크기는 일반화 성능에 영향을 미치지 않고 훈련 시간을 매우 단축시킴\n",
    "\n",
    "### Activation Function\n",
    "* 일반적으로 ReLU활성화 함수가 모든 은닉층에 좋은 기본값\n",
    "\n",
    "### 반복 횟수\n",
    "* 대부분의 경우 반복 횟수는 튜닝할 필요 없이 조기 종료를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-shore",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
